{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal\n",
    "goal = \"Convert a long YouTube transcript into structured notes and diagrams for a local material-mkdocs site.\"\n",
    "\n",
    "# tasks\n",
    "task_1 = \"Download the complete transcript from the YouTube video.\"\n",
    "task_2 = \"Collect video metadata (title, author, date) from YouTube.\"\n",
    "task_3 = \"Identify key topics, keywords and questions from the transcript.\"\n",
    "task_4 = \"Draft an outline with clear sections and subsections based on the concatenated content from the previous tasks.\"\n",
    "task_5 = \"Populate each section and subsection in the outline with detailed content.\"\n",
    "task_6 = \"Create relevant mermaid diagrams and integrate them into the content.\"\n",
    "task_7 = \"Assemble each section into individual Markdown files, including relevant diagrams and metadata.\"\n",
    "task_8 = \"Compile all Markdown files into the material-mkdocs site structure.\"\n",
    "task_9 = \"Launch the local mkdocs site to verify the structure and content.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls\n",
    "\n",
    "url_1 = \"https://www.youtube.com/watch?v=hvAPnpSfSGo\" # langraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things I want to try\n",
    "\n",
    "- [X] cost decorator\n",
    "- [ ] try different models\n",
    "- [X] improve my video_id function\n",
    "- [ ] like Josh's idea of replace the website domain and get a custom site\n",
    "- [ ] try Surya\n",
    "- [X] make url a const\n",
    "- [ ] router run everything in sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import enum\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "from pydantic import BaseModel, Field, StringConstraints, UUID4, conlist, constr, field_validator\n",
    "import tiktoken\n",
    "import time\n",
    "from typing import Any, Callable, ClassVar, Dict, Iterable, List, Optional, Type, Union\n",
    "from typing_extensions import Annotated, Literal\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter, TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "\n",
    "dotenv_path = Path(r\"C:\\Storage\\python_projects\\ashvin\\.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "# main constants\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\" # points to latest GPT model\n",
    "URL = url_1\n",
    "\n",
    "\n",
    "#instantiate client\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.TOOLS)\n",
    "audio_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost decorator\n",
    "\n",
    "def cost(function: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator to calculate and add the cost of token usage based on predefined model pricing.\n",
    "    \n",
    "    This decorator enriches the output of the decorated function by calculating the cost\n",
    "    based on the number of prompt and completion tokens used. The costs are computed\n",
    "    according to a hardcoded pricing table for supported models.\n",
    "\n",
    "    Args:\n",
    "        function (Callable): The function to be decorated, expected to return an instance\n",
    "                             of a model with token counts included.\n",
    "\n",
    "    Returns:\n",
    "        Callable: A decorator that enhances the function's output with cost calculations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the pricing table within the decorator\n",
    "    pricing = {\n",
    "        'gpt-4o': {\n",
    "            'input': 5.00 / 1000000,  # $5.00 per 1M tokens\n",
    "            'output': 15.00 / 1000000  # $15.00 per 1M tokens\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def decorated_function(*args, **kwargs) -> Dict[str, Any]:\n",
    "        # Call the original function and capture its output\n",
    "        result = function(*args, **kwargs)\n",
    "        \n",
    "        # Extract token counts using dot notation\n",
    "        prompt_tokens = result.token_counts.prompt_tokens\n",
    "        completion_tokens = result.token_counts.completion_tokens\n",
    "\n",
    "        # Determine the model used; default to 'gpt-4o' for now\n",
    "        model = 'gpt-4o'  # This could be dynamically determined based on args/kwargs if needed\n",
    "\n",
    "        # Calculate costs based on the price table for the specific model\n",
    "        input_cost = prompt_tokens * pricing[model]['input']\n",
    "        output_cost = completion_tokens * pricing[model]['output']\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        # Format and assign cost details\n",
    "        result.cost_details = {\n",
    "            'input_cost': f\"${input_cost:.6f}\",\n",
    "            'output_cost': f\"${output_cost:.6f}\",\n",
    "            'total_cost': f\"${total_cost:.6f}\"\n",
    "        }\n",
    "\n",
    "        # Optionally print cost details for transparency\n",
    "        print(f\"Cost Details: {result.cost_details}\")\n",
    "        return result\n",
    "\n",
    "    return decorated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 cost decorator\n",
    "\n",
    "class CostDetails(BaseModel):\n",
    "    input_cost: float\n",
    "    output_cost: float\n",
    "    total_cost: float\n",
    "\n",
    "    def formatted_input_cost(self):\n",
    "        return f\"${self.input_cost:.6f}\"\n",
    "\n",
    "    def formatted_output_cost(self):\n",
    "        return f\"${self.output_cost:.6f}\"\n",
    "\n",
    "    def formatted_total_cost(self):\n",
    "        return f\"${self.total_cost:.6f}\"\n",
    "\n",
    "def cost(function: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator to calculate and add the cost of token usage based on predefined model pricing.\n",
    "    \n",
    "    This decorator enriches the output of the decorated function by calculating the cost\n",
    "    based on the number of prompt and completion tokens used. The costs are computed\n",
    "    according to a hardcoded pricing table for supported models.\n",
    "\n",
    "    Args:\n",
    "        function (Callable): The function to be decorated, expected to return an instance\n",
    "                             of a model with token counts included.\n",
    "\n",
    "    Returns:\n",
    "        Callable: A decorator that enhances the function's output with cost calculations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the pricing table within the decorator\n",
    "    pricing = {\n",
    "        'gpt-4o': {\n",
    "            'input': 5.00 / 1000000,  # $5.00 per 1M tokens\n",
    "            'output': 15.00 / 1000000  # $15.00 per 1M tokens\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def decorated_function(*args, **kwargs) -> Any:\n",
    "        # Call the original function and capture its output\n",
    "        result = function(*args, **kwargs)\n",
    "        \n",
    "        # Extract token counts using dot notation\n",
    "        prompt_tokens = result.token_counts.prompt_tokens\n",
    "        completion_tokens = result.token_counts.completion_tokens\n",
    "\n",
    "        # Determine the model used; default to 'gpt-4o' for now\n",
    "        model = 'gpt-4o'  # This could be dynamically determined based on args/kwargs if needed\n",
    "\n",
    "        # Calculate costs based on the price table for the specific model\n",
    "        input_cost = prompt_tokens * pricing[model]['input']\n",
    "        output_cost = completion_tokens * pricing[model]['output']\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        # Assign cost details using the CostDetails model\n",
    "        result.cost_details = CostDetails(\n",
    "            input_cost=input_cost,\n",
    "            output_cost=output_cost,\n",
    "            total_cost=total_cost\n",
    "        )\n",
    "\n",
    "        # Optionally print formatted cost details for transparency\n",
    "        print(f\"Cost Details: Input: {result.cost_details.formatted_input_cost()}, Output: {result.cost_details.formatted_output_cost()}, Total: {result.cost_details.formatted_total_cost()}\")\n",
    "        return result\n",
    "\n",
    "    return decorated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "\n",
    "@cost\n",
    "def wrapper(\n",
    "    system_prompt: str | None = None, \n",
    "    user_prompt: Union[str, List[str]] | None = None, \n",
    "    response_model: BaseModel | None = None, \n",
    "    max_retries: int = 3, \n",
    "    additional_messages: Union[str, List[str]] | None = None\n",
    ") -> 'WrapperOutput':\n",
    "    \"\"\"\n",
    "    Generates LLM completions using provided parameters and collects token usage information.\n",
    "    \n",
    "    This function dynamically constructs a message array for the LLM based on input parameters,\n",
    "    handles the completion process using either standard or model-based completions depending on \n",
    "    the presence of a response model, and returns structured outputs including both the completion \n",
    "    response and token usage statistics.\n",
    "\n",
    "    Args:\n",
    "        system_prompt (str, optional): System-level initial prompt or instruction.\n",
    "        user_prompt (Union[str, List[str]], optional): User-provided content or context as a single string or list of strings.\n",
    "        response_model (BaseModel, optional): Pydantic model to structure the response when using model-specific completions.\n",
    "        max_retries (int): Maximum number of retries for the LLM request.\n",
    "        additional_messages (Union[str, List[str]], optional): Additional messages to precede the user prompt.\n",
    "\n",
    "    Returns:\n",
    "        WrapperOutput: A Pydantic model containing the LLM response and detailed token counts.\n",
    "\n",
    "    Classes Defined Inside:\n",
    "        TokenCounts: A Pydantic model detailing the counts of different types of tokens.\n",
    "        WrapperOutput: A Pydantic model encapsulating the response and TokenCounts model.\n",
    "    \"\"\"\n",
    "\n",
    "    class TokenCounts(BaseModel):\n",
    "        completion_tokens: int\n",
    "        prompt_tokens: int\n",
    "        total_tokens: int\n",
    "\n",
    "    class WrapperOutput(BaseModel):\n",
    "        response: Union[str, BaseModel]\n",
    "        token_counts: TokenCounts\n",
    "        cost_details: Optional[Dict[str, str]] = None\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    # Construct the messages list based on provided inputs\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    if additional_messages:\n",
    "        # Can handle both list of messages or a single string\n",
    "        if isinstance(additional_messages, List):\n",
    "            messages.extend([{\"role\": \"user\", \"content\": message} for message in additional_messages])\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": additional_messages})\n",
    "\n",
    "    if user_prompt:\n",
    "        # Similarly, handles both single and multiple user prompts\n",
    "        if isinstance(user_prompt, List):\n",
    "            messages.extend([{\"role\": \"user\", \"content\": context} for context in user_prompt])\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Generate the completion and extract token counts based on the presence of a response model\n",
    "    if response_model is None:\n",
    "        # Standard completion process without a structured model\n",
    "        completion = client.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            response_model=None,\n",
    "            max_retries=max_retries,\n",
    "            messages=messages\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content.strip()\n",
    "        token_counts = TokenCounts(\n",
    "            completion_tokens=completion.usage.completion_tokens,\n",
    "            prompt_tokens=completion.usage.prompt_tokens,\n",
    "            total_tokens=completion.usage.total_tokens\n",
    "        )\n",
    "    else:\n",
    "        # Model-based completion that structures the response as per the specified BaseModel\n",
    "        structured_response, raw_completion = client.chat.completions.create_with_completion(\n",
    "            model=GPT_MODEL,\n",
    "            response_model=response_model,\n",
    "            max_retries=max_retries,\n",
    "            messages=messages\n",
    "        )\n",
    "        response_content = structured_response\n",
    "        token_counts = TokenCounts(\n",
    "            completion_tokens=raw_completion.usage.completion_tokens,\n",
    "            prompt_tokens=raw_completion.usage.prompt_tokens,\n",
    "            total_tokens=raw_completion.usage.total_tokens\n",
    "        )\n",
    "\n",
    "    return WrapperOutput(response=response_content, token_counts=token_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.000080, Output: $0.001995, Total: $0.002075\n"
     ]
    }
   ],
   "source": [
    "completion = wrapper(\n",
    "    system_prompt=\"Write me a short story of 100 words\",\n",
    "    response_model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Cost: $0.000080000000000000006544244313\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The completion type is : <class '__main__.wrapper.<locals>.WrapperOutput'>\"\n",
      "(\"The completion is : response='In the heart of Willowbrook, young Emma found \"\n",
      " 'a diary in an abandoned trunk. The pages, yellowed with age, told the story '\n",
      " 'of Lina, a girl who lived a century ago. Emma read about Lina’s dreams, '\n",
      " 'adventures, and unfulfilled wish to see the world. Inspired, Emma decided to '\n",
      " 'travel, carrying Lina’s diary. She visited places Lina had only imagined, '\n",
      " 'jotting down her own experiences alongside Lina’s faded ink. Emma’s final '\n",
      " 'stop was the cliff Lina often dreamed of. She released the diary into the '\n",
      " 'wind, whispering a promise that Lina’s stories would live on, carried by the '\n",
      " \"breeze across distant lands.' \"\n",
      " 'token_counts=TokenCounts(completion_tokens=129, prompt_tokens=16, '\n",
      " \"total_tokens=145) cost_details={'input_cost': '$0.000080', 'output_cost': \"\n",
      " \"'$0.001935', 'total_cost': '$0.002015'}\")\n",
      "\n",
      "\n",
      "The completion response type is : <class 'str'>\n",
      "The completion response is : In the heart of Willowbrook, young Emma found a diary in an abandoned trunk. The pages, yellowed with age, told the story of Lina, a girl who lived a century ago. Emma read about Lina’s dreams, adventures, and unfulfilled wish to see the world. Inspired, Emma decided to travel, carrying Lina’s diary. She visited places Lina had only imagined, jotting down her own experiences alongside Lina’s faded ink. Emma’s final stop was the cliff Lina often dreamed of. She released the diary into the wind, whispering a promise that Lina’s stories would live on, carried by the breeze across distant lands.\n",
      "\n",
      "\n",
      " the completion token counts type is : <class '__main__.wrapper.<locals>.TokenCounts'>\n",
      " the completion token counts is : completion_tokens=129 prompt_tokens=16 total_tokens=145\n",
      "\n",
      "\n",
      " the completion token counts - completion tokens type is : <class 'int'>\n",
      " the completion token counts - completion tokens is : 129\n"
     ]
    }
   ],
   "source": [
    "pp(f\"The completion type is : {type(completion)}\")\n",
    "pp(f\"The completion is : {completion}\")\n",
    "print(\"\\n\")\n",
    "print(f\"The completion response type is : {type(completion.response)}\")\n",
    "print(f\"The completion response is : {completion.response}\")\n",
    "print(\"\\n\")\n",
    "print(f\" the completion token counts type is : {type(completion.token_counts)}\")\n",
    "print(f\" the completion token counts is : {(completion.token_counts)}\")\n",
    "print(\"\\n\")\n",
    "print(f\" the completion token counts - completion tokens type is : {type(completion.token_counts.completion_tokens)}\")\n",
    "print(f\" the completion token counts - completion tokens is : {completion.token_counts.completion_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UserExtract(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "completion = wrapper(\n",
    "    system_prompt=\"extract the user details\",\n",
    "    user_prompt=\"Jason is a 25 year old asian male\",\n",
    "    response_model=UserExtract\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(f\"The completion type is : {type(completion)}\")\n",
    "pp(f\"The completion is : {completion}\")\n",
    "print(\"\\n\")\n",
    "print(f\"The completion response type is : {type(completion.response)}\")\n",
    "print(f\"The completion response is : {completion.response}\")\n",
    "print(\"\\n\")\n",
    "print(f\" the completion token counts type is : {type(completion.token_counts)}\")\n",
    "print(f\" the completion token counts is : {(completion.token_counts)}\")\n",
    "print(\"\\n\")\n",
    "print(f\" the completion token counts - completion tokens type is : {type(completion.token_counts.completion_tokens)}\")\n",
    "print(f\" the completion token counts - completion tokens is : {completion.token_counts.completion_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.cost_details\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
