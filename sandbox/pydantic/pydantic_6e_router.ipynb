{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal** : Convert youtube video podcasts into concise audio summaries\n",
    "\n",
    "**Plan** : \n",
    "\n",
    "- Task 1 : Retrieve Transcripts: Download transcripts from YouTube video podcasts\n",
    "- Task 2 : Summarise Transcripts: Generate concise summaries from downloaded transcripts\n",
    "- Task 3 : Convert Summaries to Audio: Use text-to-speech to create audio summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import enum\n",
    "import instructor\n",
    "import os\n",
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "from pydantic import BaseModel, Field, StringConstraints, conlist, field_validator\n",
    "from typing import Any, ClassVar, Dict, Iterable, List, Optional, Type, Union\n",
    "from typing_extensions import Annotated, Literal\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter, TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "\n",
    "dotenv_path = Path(r\"C:\\Storage\\python_projects\\ashvin\\.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# main constants\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\" # points to latest GPT model\n",
    "\n",
    "#instantiate client\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.TOOLS)\n",
    "audio_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "\n",
    "def wrapper(\n",
    "    system_prompt: str | None = None, \n",
    "    user_prompt: Union[str, list] | None = None, \n",
    "    response_model: BaseModel | None = None, \n",
    "    max_retries: int = 3, \n",
    "    additional_messages: Union[str, List[str]] | None = None\n",
    "):\n",
    "    \"\"\"Wrapper function to generate LLM completion\"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # Add system prompt if provided\n",
    "    if system_prompt is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    # Add additional messages before user_prompt\n",
    "    if additional_messages is not None:\n",
    "        if isinstance(additional_messages, list):\n",
    "            for message in additional_messages:\n",
    "                messages.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": additional_messages})\n",
    "\n",
    "    # Add user context if provided\n",
    "    if user_prompt is not None:\n",
    "        if isinstance(user_prompt, list):\n",
    "            for context in user_prompt:\n",
    "                messages.append({\"role\": \"user\", \"content\": context})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Generate the completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        response_model=response_model,\n",
    "        max_retries=max_retries,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Check if response_model is None and return appropriate result\n",
    "    if response_model is None:\n",
    "        return completion.choices[0].message.content.strip()\n",
    "    else:\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript tool\n",
    "\n",
    "class Transcript(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the YouTube video ID from a given URL, retrieves the transcript, and \n",
    "    formats it as a JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract the YouTube video ID from a given URL, retrieve the transcript,\n",
    "        and format it as a JSON string.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The YouTube URL from which to extract the video ID.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The JSON formatted transcript if the video ID is valid and the\n",
    "                           transcript is available, otherwise None.\n",
    "        \"\"\"\n",
    "        # Regular expression to find the video ID in a YouTube URL\n",
    "        pattern = r'(?:https?://)?(?:www\\.)?youtube\\.com/watch\\?v=([a-zA-Z0-9_-]{11})'\n",
    "        match = re.search(pattern, url)\n",
    "        if not match:\n",
    "            print(\"No valid YouTube video ID found in the provided URL.\")\n",
    "            return None\n",
    "\n",
    "        video_id = match.group(1)\n",
    "\n",
    "        try:\n",
    "            # Retrieve the transcript\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "            # Format the transcript as JSON\n",
    "            formatter = JSONFormatter()\n",
    "            json_formatted_transcript = formatter.format_transcript(transcript)\n",
    "\n",
    "            return json_formatted_transcript\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving or formatting transcript: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary tool\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool summarises a given input text\n",
    "    \"\"\"\n",
    "\n",
    "    summary: str = Field(None, description=\"A clear, concise summary of the text in under 50 words.\")\n",
    "    \n",
    "    def run(self, text: str) -> 'Summary':\n",
    "        \"\"\"\n",
    "        Summarize the input text.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text to summarize.\n",
    "\n",
    "        Returns:\n",
    "            Summary: An instance of the Summary class with the summarized text.\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt: str = \"\"\"\n",
    "        You are an expert podcast summarizer, condensing information into digestible summaries with appropriate signposting.\n",
    "        Provide a concise, clear, and understandable summary of the given text. \n",
    "        Include upfront a one sentence TL;DR\n",
    "        \"\"\"\n",
    "        completion = wrapper(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=text,\n",
    "            response_model=Summary,  \n",
    "            max_retries=3\n",
    "        )\n",
    "\n",
    "        return completion.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to speech tool\n",
    "\n",
    "class TextToSpeech(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool converts input text into speech using the OpenAI text-to-speech API and saves it as an MP3 file.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, text: str, model: str = \"tts-1\", voice: str = \"alloy\", speed: float = 1.0, response_format: str = \"mp3\", filename: str = \"speech\") -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Convert input text into speech and save it as an MP3 file.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The text to convert into speech.\n",
    "            model (str): The TTS model to use. Defaults to \"tts-1\".\n",
    "            voice (str): The voice to use for the speech. Defaults to \"alloy\".\n",
    "            speed (float): The speed of the speech. Defaults to 1.0.\n",
    "            response_format (str): The format of the output audio file. Defaults to \"mp3\".\n",
    "            filename (str): The name of the output file (without extension). Defaults to \"speech\".\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The path to the saved MP3 file if successful, otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate the speech\n",
    "            response = audio_client.audio.speech.create(\n",
    "                model=model,\n",
    "                voice=voice,\n",
    "                input=text,\n",
    "                speed=speed,\n",
    "                response_format=response_format\n",
    "            )\n",
    "\n",
    "            # Define the path to save the audio file\n",
    "            speech_file_path = Path(os.getcwd()) / f\"{filename}.{response_format}\"\n",
    "\n",
    "            # Save the audio content to the file\n",
    "            response.stream_to_file(speech_file_path)\n",
    "\n",
    "            # Print the file path for easy access\n",
    "            print(f\"Saved speech file at: {speech_file_path}\")\n",
    "\n",
    "            return str(speech_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating or saving speech: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fallback(BaseModel):\n",
    "    \"\"\"\n",
    "    A fallback tool to be selected when the other tools are not appropriate.\n",
    "\n",
    "    This class serves as a placeholder or default option in cases where no other \n",
    "    specific tool is suitable for the given task. It can be used to provide a \n",
    "    default response or action.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "\n",
    "class Tools(BaseModel):\n",
    "    \"\"\"\n",
    "    This class represents available tools for the user's context.\n",
    "    \n",
    "    Attributes:\n",
    "        tools: (Union[Transcript, Summary, TextToSpeech, Fallback]): Available tool classes\n",
    "    \"\"\"\n",
    "    tools: Union[Transcript, Summary, TextToSpeech, Fallback]\n",
    "\n",
    "    tool_class_mapping: ClassVar[Dict[str, Type[BaseModel]]] = {\n",
    "        \"Transcript\": Transcript,\n",
    "        \"Summary\": Summary,\n",
    "        \"TextToSpeech\": TextToSpeech,\n",
    "        \"Fallback\": Fallback\n",
    "    }   \n",
    "\n",
    "# tool title\n",
    "\n",
    "class ToolTitle(BaseModel):\n",
    "    \"\"\"\n",
    "    This class represents the title of the most relevant tool selected for the user's context.\n",
    "    \n",
    "    Attributes:\n",
    "        tool_title (str): The title of the single most relevant tool selected for the user's context.\n",
    "                          This attribute provides a clear and concise identifier for the selected tool,\n",
    "                          which is determined based on the user's prompt or context.\n",
    "    \"\"\"\n",
    "\n",
    "    tool_title: str = Field(..., description=\"The title of the single most relevant tool selected for the user's context\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# router \n",
    "\n",
    "# bug note 1 : maybe using Literal for the string enforces better checking for tool_title?\n",
    "\n",
    "class Router(BaseModel):\n",
    "    \"\"\"\n",
    "    Router tool for selecting the appropriate tool based on user prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    # tool_class_mapping: Dict[str, Type[BaseModel]] = {\n",
    "    #     \"Transcript\": Transcript,\n",
    "    #     \"Summary\": Summary,\n",
    "    #     \"TextToSpeech\": TextToSpeech,\n",
    "    #     \"Fallback\": Fallback\n",
    "    # }\n",
    "\n",
    "    def select(self, user_prompt: str) -> ToolTitle:\n",
    "        \"\"\"\n",
    "        Select the appropriate tool based on the user prompt.\n",
    "\n",
    "        Parameters:\n",
    "            user_prompt (str): The user prompt to guide tool selection.\n",
    "\n",
    "        Returns:\n",
    "            Select: The single selected tool as appropriate to the user prompt.\n",
    "        \"\"\"\n",
    "\n",
    "        tools = Tools.model_json_schema()\n",
    "        system_prompt: str = f\"You are an intelligent tool selector. Select and return the single right tool for the user from this list : {tools}\"\n",
    "\n",
    "        completion = wrapper(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=f\"Select and return the single relevant tool title for : {user_prompt}\",\n",
    "            response_model=ToolTitle,\n",
    "            max_retries=3\n",
    "        )\n",
    "        return completion\n",
    "    \n",
    "    def run(self, user_prompt: str, input_data: Any = None) -> Any:\n",
    "        \"\"\"\n",
    "        Run the appropriate tool based on the user prompt and input data.\n",
    "\n",
    "        Parameters:\n",
    "            user_prompt (str): The user prompt to guide tool selection.\n",
    "            input_data (Any): The input data to pass to the tool's run method.\n",
    "\n",
    "        Returns:\n",
    "            Any: The result of the tool's run method.\n",
    "        \"\"\"\n",
    "        # Call the select method to get the appropriate tool\n",
    "        selected_tool = self.select(user_prompt)\n",
    "        \n",
    "        # Extract the tool_title\n",
    "        tool_title = selected_tool.tool_title\n",
    "        \n",
    "        # Instantiate the appropriate tool class based on the tool_title\n",
    "        tool_class = Tools.tool_class_mapping.get(tool_title, Fallback)\n",
    "        tool_instance = tool_class()\n",
    "        \n",
    "        # Invoke the run method of the tool instance\n",
    "        result = tool_instance.run(input_data)\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1 = \"Task 1 : Retrieve Transcripts: Download transcripts from YouTube video podcasts\"\n",
    "task_2 = \"Task 2 : Summarise Transcripts: Generate concise summaries from downloaded transcripts\"\n",
    "task_3 = \"Task 3 : Convert Summaries to Audio: Use text-to-speech to create audio summaries\"\n",
    "task_4 = \"Task 4 : Add numbers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolTitle(tool_title='Fallback')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router = Router()\n",
    "response = router.select(task_4)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved speech file at: c:\\Storage\\python_projects\\ashvin\\sandbox\\pydantic\\speech.mp3\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=sGpV7_2qnSw\"\n",
    "router = Router()\n",
    "response_1 = router.run(task_1, url)\n",
    "response_2 = router.run(task_2, response_1)\n",
    "response_3 = router.run(task_3, response_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
