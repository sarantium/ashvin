#How to Fix SB 1047 and Regulate for AI Safety

### Provide Recommendations to Modify SB 1047 to Avoid Hindering Open Source AI while Ensuring Safety

To avoid the pitfalls of SB 1047 and still achieve safety in AI, the legislation should be revised to focus on deployed systems rather than released models.

- **Regulating AI System Deployment**: Shift focus from model releases to the deployment of AI systems, ensuring safety checks and regulations are applied where the AI interacts with users or other systems.

  Example: Define “covered systems” clearly and ensure compliance with safety standards.

- **Challenges and Solutions**: Address the technical and operational challenges of such regulation.

  Example: Implement clear guidelines for internal deployment monitoring and control mechanisms.

- **Avoiding Politicization**: Craft regulations that avoid driving AI development to other jurisdictions, ensuring that core AI research remains within a regulatory framework that prioritizes safety and innovation.

  Example: Ensure laws align with federal policies to avoid inter-state conflicts.

- **Ensuring Compliance**: Provide clear, actionable guidance for compliance with AI safety regulations.

  Example: Offer resources and support for developers to meet safety standards while fostering innovation.

> **Callout:** “Effective AI legislation requires a deep understanding of the distinctions between deploying and releasing models. Misguided regulation can stifle innovation and lead to unintended consequences.”