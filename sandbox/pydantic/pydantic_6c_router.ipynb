{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal** : Convert youtube video podcasts into concise audio summaries\n",
    "\n",
    "**Plan** : \n",
    "\n",
    "- Task 1 : Retrieve Transcripts: Download transcripts from YouTube video podcasts\n",
    "- Task 2 : Summarise Transcripts: Generate concise summaries from downloaded transcripts\n",
    "- Task 3 : Convert Summaries to Audio: Use text-to-speech to create audio summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import enum\n",
    "import instructor\n",
    "import os\n",
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "from pydantic import BaseModel, Field, StringConstraints, conlist, field_validator\n",
    "from typing import Any, ClassVar, Iterable, List, Optional, Type, Union\n",
    "from typing_extensions import Annotated, Literal\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter, TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "\n",
    "dotenv_path = Path(r\"C:\\Storage\\python_projects\\ashvin\\.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# main constants\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\" # points to latest GPT model\n",
    "\n",
    "#instantiate client\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.TOOLS)\n",
    "audio_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "\n",
    "def wrapper(\n",
    "    system_prompt: str | None = None, \n",
    "    user_prompt: Union[str, list] | None = None, \n",
    "    response_model: BaseModel | None = None, \n",
    "    max_retries: int = 3, \n",
    "    additional_messages: Union[str, List[str]] | None = None\n",
    "):\n",
    "    \"\"\"Wrapper function to generate LLM completion\"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # Add system prompt if provided\n",
    "    if system_prompt is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    # Add additional messages before user_prompt\n",
    "    if additional_messages is not None:\n",
    "        if isinstance(additional_messages, list):\n",
    "            for message in additional_messages:\n",
    "                messages.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": additional_messages})\n",
    "\n",
    "    # Add user context if provided\n",
    "    if user_prompt is not None:\n",
    "        if isinstance(user_prompt, list):\n",
    "            for context in user_prompt:\n",
    "                messages.append({\"role\": \"user\", \"content\": context})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Generate the completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        response_model=response_model,\n",
    "        max_retries=max_retries,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Check if response_model is None and return appropriate result\n",
    "    if response_model is None:\n",
    "        return completion.choices[0].message.content.strip()\n",
    "    else:\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript tool\n",
    "\n",
    "class Transcript(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the YouTube video ID from a given URL, retrieves the transcript, and \n",
    "    formats it as a JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract the YouTube video ID from a given URL, retrieve the transcript,\n",
    "        and format it as a JSON string.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The YouTube URL from which to extract the video ID.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The JSON formatted transcript if the video ID is valid and the\n",
    "                           transcript is available, otherwise None.\n",
    "        \"\"\"\n",
    "        # Regular expression to find the video ID in a YouTube URL\n",
    "        pattern = r'(?:https?://)?(?:www\\.)?youtube\\.com/watch\\?v=([a-zA-Z0-9_-]{11})'\n",
    "        match = re.search(pattern, url)\n",
    "        if not match:\n",
    "            print(\"No valid YouTube video ID found in the provided URL.\")\n",
    "            return None\n",
    "\n",
    "        video_id = match.group(1)\n",
    "\n",
    "        try:\n",
    "            # Retrieve the transcript\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "            # Format the transcript as JSON\n",
    "            formatter = JSONFormatter()\n",
    "            json_formatted_transcript = formatter.format_transcript(transcript)\n",
    "\n",
    "            return json_formatted_transcript\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving or formatting transcript: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary tool\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool summarises a given input text\n",
    "    \"\"\"\n",
    "\n",
    "    summary: str = Field(None, description=\"A clear, concise summary of the text in under 50 words.\")\n",
    "    \n",
    "    def run(self, text: str) -> 'Summary':\n",
    "        \"\"\"\n",
    "        Summarize the input text.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text to summarize.\n",
    "\n",
    "        Returns:\n",
    "            Summary: An instance of the Summary class with the summarized text.\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt: str = \"\"\"\n",
    "        You are an expert podcast summarizer, condensing information into digestible summaries with appropriate signposting.\n",
    "        Provide a concise, clear, and understandable summary of the given text. \n",
    "        Include upfront a one sentence TL;DR\n",
    "        \"\"\"\n",
    "        completion = wrapper(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=text,\n",
    "            response_model=Summary,  \n",
    "            max_retries=3\n",
    "        )\n",
    "\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to speech tool\n",
    "\n",
    "class TextToSpeech(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool converts input text into speech using the OpenAI text-to-speech API and saves it as an MP3 file.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, text: str, model: str = \"tts-1\", voice: str = \"alloy\", speed: float = 1.0, response_format: str = \"mp3\", filename: str = \"speech\") -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Convert input text into speech and save it as an MP3 file.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The text to convert into speech.\n",
    "            model (str): The TTS model to use. Defaults to \"tts-1\".\n",
    "            voice (str): The voice to use for the speech. Defaults to \"alloy\".\n",
    "            speed (float): The speed of the speech. Defaults to 1.0.\n",
    "            response_format (str): The format of the output audio file. Defaults to \"mp3\".\n",
    "            filename (str): The name of the output file (without extension). Defaults to \"speech\".\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The path to the saved MP3 file if successful, otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate the speech\n",
    "            response = audio_client.audio.speech.create(\n",
    "                model=model,\n",
    "                voice=voice,\n",
    "                input=text,\n",
    "                speed=speed,\n",
    "                response_format=response_format\n",
    "            )\n",
    "\n",
    "            # Define the path to save the audio file\n",
    "            speech_file_path = Path(os.getcwd()) / f\"{filename}.{response_format}\"\n",
    "\n",
    "            # Save the audio content to the file\n",
    "            response.stream_to_file(speech_file_path)\n",
    "\n",
    "            # Print the file path for easy access\n",
    "            print(f\"Saved speech file at: {speech_file_path}\")\n",
    "\n",
    "            return str(speech_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating or saving speech: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fallback class\n",
    "\n",
    "class Fallback(BaseModel):\n",
    "    message: str = \"A fallback tool to be selected when the other tools are not appropriate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector\n",
    "\n",
    "class Select(BaseModel):\n",
    "    \"\"\"\n",
    "    This class represents the selection of the most relevant tool for the user's context.\n",
    "    \n",
    "    Attributes:\n",
    "        tool_choice (Union[Transcript, Summary, TextToSpeech, Fallback]): A union of available tool classes from which only the single most relevant one is selected.\n",
    "        tool_title (str): The title of the single most relevant tool. Must be one of the tool classes.\n",
    "    \"\"\"\n",
    "    tool_choice: Union[Transcript, Summary, TextToSpeech, Fallback]\n",
    "    tool_title: str = Field(..., description=\"The title of the single most relevant tool selected for the user's context\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# router \n",
    "\n",
    "# bug note 1 : maybe using Literal for the string enforces better checking for tool_title?\n",
    "# bug note 2 : persistently in tool_choice always returns transcript only\n",
    "# option : discard instructor and go organic on tool choice with router? [Seems like a good option tbh and reduces dependency]\n",
    "# option : add a tools class with a list of tools then add a too choice class as select one from the list of tools\n",
    "\n",
    "class Router(BaseModel):\n",
    "    \"\"\"\n",
    "    Router tool for selecting the appropriate tool based on user prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    tool_class_mapping: ClassVar[dict[str, Type[BaseModel]]] = {\n",
    "        \"Transcript\": Transcript,\n",
    "        \"Summary\": Summary,\n",
    "        \"TextToSpeech\": TextToSpeech,\n",
    "        \"Fallback\": Fallback\n",
    "    }\n",
    "\n",
    "    def select(self, user_prompt: str) -> Select:\n",
    "        \"\"\"\n",
    "        Select the appropriate tool based on the user prompt.\n",
    "\n",
    "        Parameters:\n",
    "            user_prompt (str): The user prompt to guide tool selection.\n",
    "\n",
    "        Returns:\n",
    "            Select: The single selected tool as appropriate to the user prompt.\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt: str = \"You are an intelligent tool selector. Select and return the single right tool for the user.\"\n",
    "\n",
    "        completion = wrapper(\n",
    "            system_prompt=system_prompt,\n",
    "            # user_prompt=f\"Select and return the title of the single relevant tool for {user_prompt}\",\n",
    "            user_prompt=f\"Select and return the single relevant tool and tool title for : {user_prompt}\",\n",
    "            response_model=Select,\n",
    "            max_retries=3\n",
    "        )\n",
    "        return completion\n",
    "    \n",
    "    def run(self, user_prompt: str, input_data: Any = None) -> Any:\n",
    "        \"\"\"\n",
    "        Run the appropriate tool based on the user prompt and input data.\n",
    "\n",
    "        Parameters:\n",
    "            user_prompt (str): The user prompt to guide tool selection.\n",
    "            input_data (Any): The input data to pass to the tool's run method.\n",
    "\n",
    "        Returns:\n",
    "            Any: The result of the tool's run method.\n",
    "        \"\"\"\n",
    "        # Call the select method to get the appropriate tool\n",
    "        selected_tool = self.select(user_prompt)\n",
    "        \n",
    "        # Extract the tool_title\n",
    "        tool_title = selected_tool.tool_title\n",
    "        \n",
    "        # Instantiate the appropriate tool class based on the tool_title\n",
    "        tool_class = self.tool_class_mapping.get(tool_title, Fallback)\n",
    "        tool_instance = tool_class()\n",
    "        \n",
    "        # Invoke the run method of the tool instance\n",
    "        result = tool_instance.run(input_data)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'Fallback': {'properties': {'message': {'default': 'A fallback tool to be selected when the other tools are not appropriate',\n",
       "     'title': 'Message',\n",
       "     'type': 'string'}},\n",
       "   'title': 'Fallback',\n",
       "   'type': 'object'},\n",
       "  'Summary': {'description': 'This tool summarises a given input text',\n",
       "   'properties': {'summary': {'default': None,\n",
       "     'description': 'A clear, concise summary of the text in under 50 words.',\n",
       "     'title': 'Summary',\n",
       "     'type': 'string'}},\n",
       "   'title': 'Summary',\n",
       "   'type': 'object'},\n",
       "  'TextToSpeech': {'description': 'This tool converts input text into speech using the OpenAI text-to-speech API and saves it as an MP3 file.',\n",
       "   'properties': {},\n",
       "   'title': 'TextToSpeech',\n",
       "   'type': 'object'},\n",
       "  'Transcript': {'description': 'This tool extracts the YouTube video ID from a given URL, retrieves the transcript, and \\nformats it as a JSON string.',\n",
       "   'properties': {},\n",
       "   'title': 'Transcript',\n",
       "   'type': 'object'}},\n",
       " 'description': \"This class represents the selection of the most relevant tool for the user's context.\\n\\nAttributes:\\n    tool_choice (Union[Transcript, Summary, TextToSpeech, Fallback]): A union of available tool classes.\\n    tool_title (str): The title of the single most relevant tool. Must be one of the tool classes.\",\n",
       " 'properties': {'tool_choice': {'anyOf': [{'$ref': '#/$defs/Transcript'},\n",
       "    {'$ref': '#/$defs/Summary'},\n",
       "    {'$ref': '#/$defs/TextToSpeech'},\n",
       "    {'$ref': '#/$defs/Fallback'}],\n",
       "   'title': 'Tool Choice'},\n",
       "  'tool_title': {'description': \"The title of the single most relevant tool for the user's context\",\n",
       "   'title': 'Tool Title',\n",
       "   'type': 'string'}},\n",
       " 'required': ['tool_choice', 'tool_title'],\n",
       " 'title': 'Select',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response =Select.model_json_schema()\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1 = \"Task 1 : Retrieve Transcripts: Download transcripts from YouTube video podcasts\"\n",
    "task_2 = \"Task 2 : Summarise Transcripts: Generate concise summaries from downloaded transcripts\"\n",
    "task_3 = \"Task 3 : Convert Summaries to Audio: Use text-to-speech to create audio summaries\"\n",
    "task_4 = \"Task 4 : Add numbers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Select(tool_choice=Transcript(), tool_title='TextToSpeech')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router = Router()\n",
    "response = router.select(task_3)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.tool_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "router = Router()\n",
    "response_1 = router.run(task_1, \"https://www.youtube.com/watch?v=krixaEhLnlA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = router.run(task_2, response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Elon Musk raised $6 billion for his AI startup XAI and predicted AGI would surpass humans next year, sparking debate with Meta's Chief AI scientist Yann LeCun. The podcast also discusses the financial and operational struggles of Stability AI, the shortcomings of Google's AI, privacy concerns with Meta's data policies, and skepticism around new AI products like the Humane pin and Rabbit R1. Finally, it covers OpenAI's continued efforts with GPT-5 and questions about the true motives behind AI safety discussions.\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved speech file at: c:\\Storage\\python_projects\\ashvin\\sandbox\\pydantic\\speech.mp3\n"
     ]
    }
   ],
   "source": [
    "response_3 = router.run(task_3, response_2.summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
