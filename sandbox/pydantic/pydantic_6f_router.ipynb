{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal** : Convert YouTube videos into concise audio summaries\n",
    "\n",
    "**Plan** : \n",
    "\n",
    "- Task 1 : Retrieve Video Metadata: Extract key metadata from a YouTube video\n",
    "- Task 2 : Retrieve Transcript: Download transcript from YouTube video\n",
    "- Task 3 : Summarise Transcript: Generate concise summary from downloaded transcript\n",
    "- Task 4 : Merge Metadata: Integrate key metadata into the summary before converting to audio\n",
    "- Task 5 : Convert Summary to Audio: Use text-to-speech to create audio summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Wishlist\n",
    "\n",
    "- [response tokens](https://cookbook.openai.com/examples/how_to_stream_completions#4-how-to-get-token-usage-data-for-streamed-chat-completion-response)\n",
    "- audio longer than 4 mins\n",
    "- lecture notes\n",
    "- Use Literal for toolbox?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import enum\n",
    "import instructor\n",
    "import os\n",
    "import re\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "from pydantic import BaseModel, Field, StringConstraints, conlist, field_validator\n",
    "import tiktoken\n",
    "import time\n",
    "from typing import Any, ClassVar, Dict, Iterable, List, Optional, Type, Union\n",
    "from typing_extensions import Annotated, Literal\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter, TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "\n",
    "dotenv_path = Path(r\"C:\\Storage\\python_projects\\ashvin\\.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "\n",
    "# main constants\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\" # points to latest GPT model\n",
    "\n",
    "#instantiate client\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.TOOLS)\n",
    "audio_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "\n",
    "def wrapper(\n",
    "    system_prompt: str | None = None, \n",
    "    user_prompt: Union[str, list] | None = None, \n",
    "    response_model: BaseModel | None = None, \n",
    "    max_retries: int = 3, \n",
    "    additional_messages: Union[str, List[str]] | None = None\n",
    "):\n",
    "    \"\"\"Wrapper function to generate LLM completion\"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # Add system prompt if provided\n",
    "    if system_prompt is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    # Add additional messages before user_prompt\n",
    "    if additional_messages is not None:\n",
    "        if isinstance(additional_messages, list):\n",
    "            for message in additional_messages:\n",
    "                messages.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": additional_messages})\n",
    "\n",
    "    # Add user context if provided\n",
    "    if user_prompt is not None:\n",
    "        if isinstance(user_prompt, list):\n",
    "            for context in user_prompt:\n",
    "                messages.append({\"role\": \"user\", \"content\": context})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Generate the completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        response_model=response_model,\n",
    "        max_retries=max_retries,\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    # Check if response_model is None and return appropriate result\n",
    "    if response_model is None:\n",
    "        return completion.choices[0].message.content.strip()\n",
    "    else:\n",
    "        return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube details tool\n",
    "\n",
    "class YoutubeDetails(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the YouTube video ID from a given URL, retrieves key metadata,\n",
    "    and formats it as a dictionary.\n",
    "    \n",
    "    The metadata extracted includes:\n",
    "        - Title: The title of the video.\n",
    "        - Description: The description of the video.\n",
    "        - Published At: The date and time when the video was published.\n",
    "        - Channel Title: The title of the channel that uploaded the video.\n",
    "        - Views: The number of views the video has received.\n",
    "        - Likes: The number of likes the video has received.\n",
    "        - Dislikes: The number of dislikes the video has received.\n",
    "        - Comments: The number of comments on the video.\n",
    "        - Duration: The duration of the video in ISO 8601 format.\n",
    "        - Tags: A list of tags associated with the video.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str) -> Optional[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Extract the YouTube video ID from a given URL, retrieve key metadata,\n",
    "        and format it as a dictionary.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The YouTube URL from which to extract the video ID.\n",
    "\n",
    "        Returns:\n",
    "            Optional[Dict[str, str]]: The video metadata if the video ID is valid and the\n",
    "                                      metadata is available, otherwise None.\n",
    "        \"\"\"\n",
    "        # Regular expression to find the video ID in a YouTube URL\n",
    "        pattern = r'(?:https?://)?(?:www\\.)?(?:youtube\\.com/watch\\?v=|youtu\\.be/)([a-zA-Z0-9_-]{11})'\n",
    "        match = re.search(pattern, url)\n",
    "        if not match:\n",
    "            print(\"No valid YouTube video ID found in the provided URL.\")\n",
    "            return None\n",
    "\n",
    "        video_id = match.group(1)\n",
    "\n",
    "        try:\n",
    "            if not YOUTUBE_API_KEY:\n",
    "                print(\"API key not found in environment variables.\")\n",
    "                return None\n",
    "\n",
    "            youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
    "            request = youtube.videos().list(part='snippet,contentDetails,statistics', id=video_id)\n",
    "            response = request.execute()\n",
    "\n",
    "            if not response['items']:\n",
    "                print(\"No video found with the provided video ID.\")\n",
    "                return None\n",
    "\n",
    "            video_details = response['items'][0]\n",
    "            metadata = {\n",
    "                \"Title\": video_details['snippet']['title'],\n",
    "                \"Description\": video_details['snippet']['description'],\n",
    "                \"Published At\": video_details['snippet']['publishedAt'],\n",
    "                \"Channel Title\": video_details['snippet']['channelTitle'],\n",
    "                \"Views\": video_details['statistics'].get('viewCount', 'N/A'),\n",
    "                \"Likes\": video_details['statistics'].get('likeCount', 'N/A'),\n",
    "                \"Dislikes\": video_details['statistics'].get('dislikeCount', 'N/A'),\n",
    "                \"Comments\": video_details['statistics'].get('commentCount', 'N/A'),\n",
    "                \"Duration\": video_details['contentDetails']['duration'],\n",
    "                \"Tags\": video_details['snippet'].get('tags', [])\n",
    "            }\n",
    "\n",
    "            return metadata\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving video metadata: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript tool\n",
    "\n",
    "class Transcript(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the YouTube video ID from a given URL, retrieves the transcript, and \n",
    "    formats it as a JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract the YouTube video ID from a given URL, retrieve the transcript,\n",
    "        and format it as a JSON string.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The YouTube URL from which to extract the video ID.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The JSON formatted transcript if the video ID is valid and the\n",
    "                           transcript is available, otherwise None.\n",
    "        \"\"\"\n",
    "        # Regular expression to find the video ID in a YouTube URL\n",
    "        pattern = r'(?:https?://)?(?:www\\.)?youtube\\.com/watch\\?v=([a-zA-Z0-9_-]{11})'\n",
    "        match = re.search(pattern, url)\n",
    "        if not match:\n",
    "            print(\"No valid YouTube video ID found in the provided URL.\")\n",
    "            return None\n",
    "\n",
    "        video_id = match.group(1)\n",
    "\n",
    "        try:\n",
    "            # Retrieve the transcript\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "            # Format the transcript as JSON\n",
    "            formatter = JSONFormatter()\n",
    "            json_formatted_transcript = formatter.format_transcript(transcript)\n",
    "\n",
    "            return json_formatted_transcript\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving or formatting transcript: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def count(self, url: Optional[str] = None, transcript: Optional[str] = None) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Count the number of tokens in the transcript of the YouTube video.\n",
    "\n",
    "        Parameters:\n",
    "            url (Optional[str]): The YouTube URL from which to extract the video ID.\n",
    "            transcript (Optional[str]): The pre-fetched transcript to count tokens for.\n",
    "\n",
    "        Returns:\n",
    "            Optional[int]: The number of tokens in the transcript if available, otherwise None.\n",
    "        \"\"\"\n",
    "        if transcript is None:\n",
    "            if url is None:\n",
    "                print(\"Either url or transcript must be provided.\")\n",
    "                return None\n",
    "            transcript = self.run(url)\n",
    "            if transcript is None:\n",
    "                return None\n",
    "\n",
    "        # model list here : https://github.com/openai/tiktoken/blob/main/tiktoken/model.py\n",
    "        # maybe later separate count into its' own class under Utils or something\n",
    "        \n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens = encoding.encode(transcript)\n",
    "        return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary tool\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool summarises a given input text\n",
    "    \"\"\"\n",
    "\n",
    "    summary: str = Field(None, description=\"A clear, concise summary of the text in under 500 words.\")\n",
    "    \n",
    "    def run(self, text: str) -> 'Summary':\n",
    "        \"\"\"\n",
    "        Summarize the input text.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text to summarize.\n",
    "\n",
    "        Returns:\n",
    "            Summary: An instance of the Summary class with the summarized text.\n",
    "        \"\"\"\n",
    "\n",
    "        system_prompt: str = \"\"\"\n",
    "        You are an expert in AI and science communication, able to make technical content detailed, interesting and accessible \n",
    "        - You write in the spirit of Richard Feynman, making complex concepts easy to understand without sacrificing quality. \n",
    "        - Create a long, detailed and comprehensive summary of the provided text.\n",
    "        - At least 500 words in length.\n",
    "        - Provide detail on all central ideas; also include peripheral items that are interesting\n",
    "        - Rely strictly on the provided text, without including external information.\n",
    "        - Format the summary in markdown with bullet points, signposting and any other tools for accessible reading.\n",
    "        - Ensure text is connected and clear with each sentence flowing seamlessly into the next.\n",
    "        - Have a tone of voice that is simple, clear, accessible and direct.\n",
    "        \"\"\"\n",
    "\n",
    "    # - Write a summary in the style of Raymond Carver but preserve all detail: simple, clear and direct.\n",
    "\n",
    "        completion = wrapper(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=text,\n",
    "            response_model=Summary,  \n",
    "            max_retries=3\n",
    "        )\n",
    "\n",
    "        return completion.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tool\n",
    "\n",
    "class MergeMetadata(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool merges video metadata with a summary, creating a combined summary\n",
    "    that includes a preamble with key information about the video in a concise format.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, metadata: Dict[str, str], summary: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Merge video metadata with the summary, adding a preamble with key information.\n",
    "\n",
    "        Parameters:\n",
    "            metadata (Dict[str, str]): The metadata of the YouTube video.\n",
    "            summary (str): The summary of the video's transcript.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The merged summary with metadata preamble if both summary and\n",
    "                           metadata are valid, otherwise None.\n",
    "        \"\"\"\n",
    "        if not metadata or not summary:\n",
    "            print(\"Both metadata and summary must be provided.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            title = metadata.get('Title', 'N/A')\n",
    "            published_at = metadata.get('Published At', 'N/A')\n",
    "            channel_title = metadata.get('Channel Title', 'N/A')\n",
    "            duration = metadata.get('Duration', 'N/A')\n",
    "\n",
    "            # Convert duration from ISO 8601 format to a more readable format\n",
    "            duration_minutes = self._convert_duration_to_minutes(duration)\n",
    "            # Convert the published_at date to a human-readable format\n",
    "            readable_published_at = self._convert_date_to_human_readable(published_at)\n",
    "\n",
    "            preamble = (\n",
    "                f\"This video is titled '{title}', and was published on {readable_published_at} \"\n",
    "                f\"by {channel_title} channel. It is {duration_minutes} minutes long.\"\n",
    "            )\n",
    "\n",
    "            merged_summary = f\"{preamble}\\n\\nSummary:\\n{summary}\"\n",
    "            return merged_summary\n",
    "        except Exception as e:\n",
    "            print(f\"Error merging metadata with summary: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _convert_duration_to_minutes(self, duration: str) -> str:\n",
    "        \"\"\"\n",
    "        Convert ISO 8601 duration format to total minutes.\n",
    "\n",
    "        Parameters:\n",
    "            duration (str): The ISO 8601 duration string.\n",
    "\n",
    "        Returns:\n",
    "            str: The duration in total minutes.\n",
    "        \"\"\"\n",
    "        match = re.match(r'PT(\\d+H)?(\\d+M)?(\\d+S)?', duration)\n",
    "        if not match:\n",
    "            return 'N/A'\n",
    "\n",
    "        hours = int(match.group(1)[:-1]) if match.group(1) else 0\n",
    "        minutes = int(match.group(2)[:-1]) if match.group(2) else 0\n",
    "        seconds = int(match.group(3)[:-1]) if match.group(3) else 0\n",
    "\n",
    "        total_minutes = hours * 60 + minutes + seconds / 60\n",
    "        return f\"{total_minutes:.2f}\"\n",
    "\n",
    "    def _convert_date_to_human_readable(self, date_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Convert ISO 8601 date format to a more human-readable format.\n",
    "\n",
    "        Parameters:\n",
    "            date_str (str): The ISO 8601 date string.\n",
    "\n",
    "        Returns:\n",
    "            str: The date in a human-readable format.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            return date_obj.strftime(\"%B %d, %Y\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting date: {e}\")\n",
    "            return date_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to speech tool\n",
    "\n",
    "class TextToSpeech(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool converts input text into speech using the OpenAI text-to-speech API and saves it as an MP3 file.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, text: str, model: str = \"tts-1\", voice: str = \"alloy\", speed: float = 1.0, response_format: str = \"mp3\", filename: str = \"speech\") -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Convert input text into speech and save it as an MP3 file.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The text to convert into speech.\n",
    "            model (str): The TTS model to use. Defaults to \"tts-1\".\n",
    "            voice (str): The voice to use for the speech. Defaults to \"alloy\".\n",
    "            speed (float): The speed of the speech. Defaults to 1.0.\n",
    "            response_format (str): The format of the output audio file. Defaults to \"mp3\".\n",
    "            filename (str): The name of the output file (without extension). Defaults to \"speech\".\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The path to the saved MP3 file if successful, otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate the speech\n",
    "            response = audio_client.audio.speech.create(\n",
    "                model=model,\n",
    "                voice=voice,\n",
    "                input=text,\n",
    "                speed=speed,\n",
    "                response_format=response_format\n",
    "            )\n",
    "\n",
    "            # Define the path to save the audio file\n",
    "            speech_file_path = Path(os.getcwd()) / f\"{filename}.{response_format}\"\n",
    "\n",
    "            # Save the audio content to the file\n",
    "            response.stream_to_file(speech_file_path)\n",
    "\n",
    "            # Print the file path for easy access\n",
    "            print(f\"Saved speech file at: {speech_file_path}\")\n",
    "\n",
    "            return str(speech_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating or saving speech: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fallback(BaseModel):\n",
    "    \"\"\"\n",
    "    A fallback tool to be selected when the other tools are not appropriate.\n",
    "\n",
    "    This class serves as a placeholder or default option in cases where no other \n",
    "    specific tool is suitable for the given task. It can be used to provide a \n",
    "    default response or action.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "\n",
    "class Tools(BaseModel):\n",
    "    \"\"\"\n",
    "    This class represents available tools for the user's context.\n",
    "    \n",
    "    Attributes:\n",
    "        tools: (Union[YoutubeDetails, Transcript, Summary, MergeMetadata, TextToSpeech, Fallback]): Available tool classes\n",
    "    \"\"\"\n",
    "    tools: Union[YoutubeDetails, Transcript, Summary, MergeMetadata, TextToSpeech, Fallback]\n",
    "\n",
    "    tool_class_mapping: ClassVar[Dict[str, Type[BaseModel]]] = {\n",
    "        \"YoutubeDetails\": YoutubeDetails,\n",
    "        \"Transcript\": Transcript,\n",
    "        \"Summary\": Summary,\n",
    "        \"MergeMetadata\": MergeMetadata,\n",
    "        \"TextToSpeech\": TextToSpeech,\n",
    "        \"Fallback\": Fallback,\n",
    "\n",
    "    }   \n",
    "\n",
    "# tool title\n",
    "\n",
    "class ToolTitle(BaseModel):\n",
    "    \"\"\"\n",
    "    This class represents the title of the most relevant tool selected for the user's context.\n",
    "    \n",
    "    Attributes:\n",
    "        tool_title (str): The title of the single most relevant tool selected for the user's context.\n",
    "                          This attribute provides a clear and concise identifier for the selected tool,\n",
    "                          which is determined based on the user's prompt or context.\n",
    "    \"\"\"\n",
    "\n",
    "    tool_title: str = Field(..., description=\"The title of the single most relevant tool selected for the user's context\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# router \n",
    "\n",
    "# bug note 1 : maybe using Literal for the string enforces better checking for tool_title?\n",
    "\n",
    "class Router(BaseModel):\n",
    "    \"\"\"\n",
    "    Router tool for selecting the appropriate tool based on user prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    def select(self, user_prompt: str) -> ToolTitle:\n",
    "        \"\"\"\n",
    "        Select the appropriate tool based on the user prompt.\n",
    "\n",
    "        Parameters:\n",
    "            user_prompt (str): The user prompt to guide tool selection.\n",
    "\n",
    "        Returns:\n",
    "            Select: The single selected tool as appropriate to the user prompt.\n",
    "        \"\"\"\n",
    "\n",
    "        tools = Tools.model_json_schema()\n",
    "        system_prompt: str = f\"You are an intelligent tool selector. Select and return the single right tool for the user from this list : {tools}\"\n",
    "\n",
    "        completion = wrapper(\n",
    "            system_prompt=system_prompt,\n",
    "            user_prompt=f\"Select and return the single relevant tool title for : {user_prompt}\",\n",
    "            response_model=ToolTitle,\n",
    "            max_retries=3\n",
    "        )\n",
    "        return completion\n",
    "    \n",
    "    def run(self, user_prompt: str, input_data: Any = None) -> Any:\n",
    "        \"\"\"\n",
    "        Run the appropriate tool based on the user prompt and input data.\n",
    "\n",
    "        Parameters:\n",
    "            user_prompt (str): The user prompt to guide tool selection.\n",
    "            input_data (Any): The input data to pass to the tool's run method.\n",
    "\n",
    "        Returns:\n",
    "            Any: The result of the tool's run method.\n",
    "        \"\"\"\n",
    "        # Call the select method to get the appropriate tool\n",
    "        selected_tool = self.select(user_prompt)\n",
    "        \n",
    "        # Extract the tool_title\n",
    "        tool_title = selected_tool.tool_title\n",
    "        \n",
    "        # Instantiate the appropriate tool class based on the tool_title\n",
    "        tool_class = Tools.tool_class_mapping.get(tool_title, Fallback)\n",
    "        tool_instance = tool_class()\n",
    "        \n",
    "        # Handle multiple input data\n",
    "        if isinstance(input_data, (list, tuple)):\n",
    "            result = tool_instance.run(*input_data)  # Unpacking the input data\n",
    "        else:\n",
    "            result = tool_instance.run(input_data)\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tasks\n",
    "task_1 = \"Task 1 : Retrieve Video Metadata: Extract key metadata from YouTube videos\"\n",
    "task_2 = \"Task 2 : Retrieve Transcripts: Download transcripts from YouTube video podcasts\"\n",
    "task_3 = \"Task 3 : Summarise Transcripts: Generate concise summaries from downloaded transcripts\"\n",
    "task_4 = \"Task 4 : Merge Metadata: Integrate key metadata into the summary before converting to audio\"\n",
    "task_5 = \"Task 5 : Convert Summaries to Audio: Use text-to-speech to create audio summaries\"\n",
    "\n",
    "\n",
    "# fallback task for unit testing\n",
    "task_6 = \"Task 5 : Do a matrix multiplication\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolTitle(tool_title='MergeMetadata')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test evals : tool selection\n",
    "router = Router()\n",
    "response = router.select(task_4)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved speech file at: c:\\Storage\\python_projects\\ashvin\\sandbox\\pydantic\\speech.mp3\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=MXPYbjjyHXc\"\n",
    "router = Router()\n",
    "response_1 = router.run(task_1, url)\n",
    "time.sleep(2)\n",
    "response_2 = router.run(task_2, url)\n",
    "time.sleep(2)\n",
    "response_3 = router.run(task_3, response_2)\n",
    "time.sleep(2)\n",
    "response_4 = router.run(task_4, input_data=[response_1, response_3])\n",
    "time.sleep(2)\n",
    "response_5 = router.run(task_5, response_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In the video, Lori, the VP of Developer Relations at Llama Index, introduces '\n",
      " 'and discusses the concept of context-augmented knowledge assistance, '\n",
      " 'focusing on the limitations of Retrieval-Augmented Generation (RAG) and '\n",
      " 'advocating for the use of more sophisticated agents in knowledge retrieval '\n",
      " 'tasks. She begins by explaining what Llama Index is—a framework in Python '\n",
      " 'and TypeScript for building LLM-enabled applications over data—and mentions '\n",
      " 'their monetization strategy through the Llama Cloud, which offers a hosted, '\n",
      " 'scalable data retrieval and querying system currently in beta. Additionally, '\n",
      " 'she highlights Llama Parse, a cloud service for document parsing essential '\n",
      " 'for knowledge retrieval, and mentions that it is free for up to 1,000 pages '\n",
      " 'a day with a pay-as-you-go model afterward. Lori then transitions to '\n",
      " 'discussing why naive RAG pipelines, while effective for many tasks, have '\n",
      " 'limitations, especially in summarization, comparison, and multi-part '\n",
      " 'questions, which require more than just simple semantic search. To solve '\n",
      " 'these limitations, Llama Index introduces agentic RAG, which incorporates '\n",
      " 'multi-turn interactions, query understanding, tool use, reflection, error '\n",
      " 'correction, and memory into the querying process. She explains various '\n",
      " 'components and strategies to achieve more sophisticated querying, such as '\n",
      " 'routing, memory, and query planning. Lori further expands on three types of '\n",
      " 'agentic reasoning loops—sequential, DAG-based, and tree-based '\n",
      " 'planning—explaining how each can enhance the querying process. Lastly, she '\n",
      " 'touches on additional features like observability, low-level control, and '\n",
      " 'customizability that Llama Index offers to give users more control over '\n",
      " 'their agents. The video concludes with Lori mentioning future areas for '\n",
      " 'development, such as multi-agent interactions, and provides links and QR '\n",
      " 'codes for additional resources.')\n"
     ]
    }
   ],
   "source": [
    "pp(response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tools.model_json_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
