{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import enum\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "from pydantic import BaseModel, Field, StringConstraints, conlist, field_validator\n",
    "from typing import List, Union, Iterable\n",
    "from typing_extensions import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "\n",
    "dotenv_path = Path(r\"C:\\Storage\\python_projects\\ashvin\\.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# main constants\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\" # points to latest GPT model\n",
    "\n",
    "#instantiate client\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.TOOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query plan primitives\n",
    "\n",
    "class QueryType(str, enum.Enum):\n",
    "    \"\"\"Enumeration representing the types of queries that can be asked to a question answer system.\"\"\"\n",
    "\n",
    "    SINGLE_QUESTION = \"SINGLE\"\n",
    "    MERGE_MULTIPLE_RESPONSES = \"MERGE_MULTIPLE_RESPONSES\"\n",
    "\n",
    "class Query(BaseModel):\n",
    "    \"\"\"Class representing a single question in a query plan.\"\"\"\n",
    "\n",
    "    id: int = Field(..., description=\"Unique id of the query\")\n",
    "    question: str = Field(\n",
    "        ...,\n",
    "        description=\"Question asked using a question answering system\",\n",
    "    )\n",
    "    dependencies: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of sub questions that need to be answered before asking this question\",\n",
    "    )\n",
    "    node_type: QueryType = Field(\n",
    "        default=QueryType.SINGLE_QUESTION,\n",
    "        description=\"Type of question, either a single question or a multi-question merge\",\n",
    "    )\n",
    "\n",
    "class QueryPlan(BaseModel):\n",
    "    \"\"\"Container class representing a tree of questions to ask a question answering system.\"\"\"\n",
    "\n",
    "    query_graph: List[Query] = Field(\n",
    "        ..., description=\"The query graph representing the plan\"\n",
    "    )\n",
    "\n",
    "    def _dependencies(self, ids: List[int]) -> List[Query]:\n",
    "        \"\"\"Returns the dependencies of a query given their ids.\"\"\"\n",
    "\n",
    "        return [q for q in self.query_graph if q.id in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAQ(BaseModel):\n",
    "    \"\"\"Class for a single question and answer pair\"\"\"\n",
    "\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revised wrapper\n",
    "\n",
    "def wrapper(\n",
    "    system_prompt: str | None = None, \n",
    "    user_prompt: Union[str, list] | None = None, \n",
    "    response_model: BaseModel | None = None, \n",
    "    max_retries: int = 3, \n",
    "    additional_messages: Union[str, List[str]] | None = None\n",
    "):\n",
    "    \"\"\"Wrapper function to generate LLM completion\"\"\"\n",
    "    messages = []\n",
    "\n",
    "    # Add system prompt if provided\n",
    "    if system_prompt is not None:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    # Add additional messages before user_prompt\n",
    "    if additional_messages is not None:\n",
    "        if isinstance(additional_messages, list):\n",
    "            for message in additional_messages:\n",
    "                messages.append({\"role\": \"user\", \"content\": message})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": additional_messages})\n",
    "\n",
    "    # Add user context if provided\n",
    "    if user_prompt is not None:\n",
    "        if isinstance(user_prompt, list):\n",
    "            for context in user_prompt:\n",
    "                messages.append({\"role\": \"user\", \"content\": context})\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Generate the completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        response_model=response_model,\n",
    "        max_retries=max_retries,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_system_prompt = \"\"\"\n",
    "You are a world class question and answer algorithm capable of creating exceptionally clear, concise and precise questions and answering them.\n",
    "Before you create the question-answer pairs, think step-by-step to get a better understanding of the problem, utilising any context available to you.\n",
    "Your style guide is to follow the author Raymond carver for simplicity and clarity in composing questions and answers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_user_prompt = \"\"\"\n",
    "What are a detailed list of additional question and answer pairs that may be asked of a new to be formed AI platform team in a B2B SAAS company? \n",
    "I want precise and clearly understandable questions and answers. Do not replicate any question-answer pairs from the context.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response with additional messages as context \n",
    "\n",
    "additional_messages_1 = \"\"\"\n",
    "Platform\n",
    "\n",
    "Innovations are adopted quickly if they are easy to make, easy to use, fit existing patterns, and have visible results. Generative AI has abruptly changed the innovation landscape by accelerating the utility and availability of AI products and services.\n",
    "While the vast majority of consumers and companies do not make technology, they are actively searching for value in this space. Consequently, technology companies are trying to implement AI features that create value for their customers as fast as possible.\n",
    "The long tail of B2B SaaS companies has a unique set of challenges. Many of these companies have enterprise client traction and skilled development teams but lack extra capital and in-house AI/ML resources, making it hard to bootstrap production grade AI capabilities and features.\n",
    "\n",
    "\n",
    "Goals\n",
    "A dedicated platform team helps B2B SaaS companies stay competitive by quickly matching competitors' advances and meeting client expectations for new experiences.\n",
    "This team drives innovation, positions the company as a leader in AI, and reduces risk by providing systemic infrastructure and resources to prevent project failures.\n",
    "It specifically helps:\n",
    "Product teams launch AI features\n",
    "Business teams automate workflows\n",
    "Leaders unify AI strategy, standards and voice\n",
    "Managers make data-driven decisions\n",
    "Clients adopt third-party AI products\n",
    "Staff upskill AI knowledge and fluency\n",
    "Ultimately, platform teams shape organisational culture, ensuring that responsibility and enthusiasm for AI are shared by everyone, not just a small group of evangelists.\n",
    "Good platform teams function as skunkworks, rapid execution engines, and guardrails, ensuring the company quickly and safely integrates AI across all operations in order to benefit clients and establish AI leadership amongst competitors.\n",
    "\n",
    "\n",
    "Ideas\n",
    "When bootstrapping platform teams, only speed and outcomes matter. Fast, cheap value creation determines whether platforms continue or are killed off because resources are limited, track records nonexistent and executive patience is thin.\n",
    "Platform teams must act for all functions and departments in a B2B SaaS company. They should tackle cross disciplinary needs - at least product, design and engineering to start with - and champion fairness - equitable platform access to all products - as foundational principles for success.\n",
    "Focusing on both technical tooling and service delivery is important, as the latter reduces early bottlenecks the most.\n",
    "In this environment, prioritisation is king and selecting the correct set of valuable and feasible initiatives to iterate on and build company confidence is crucial.\n",
    "Platform teams empower executives with a robust reporting framework that simplifies tracking, optimises resource allocation, and sharpens decision-making regarding AI initiatives.\n",
    "Goal 1 : Help product teams launch AI features\n",
    "\n",
    "\n",
    "KPI\n",
    "Bottleneck\n",
    "Actions\n",
    "Write PRD in 1 day \n",
    "Lack of competitor awareness and AI expertise slows opportunity identification\n",
    "1. Searchable, updated competitor and client database of AI features\n",
    "\n",
    "2. Custom GPT for rapid ideation and document formatting\n",
    "Develop prototype in 1 week\n",
    "Lack of tooling slows conversion from idea to PoC\n",
    "1. Curated, ready-to-go notebooks with composable components and pipelines to bootstrap a project\n",
    "\n",
    "2. [Optional] Buy a low/no-code service to help non-engineers prototype\n",
    "Create pitch in 1 day\n",
    "\n",
    "Approval decision in 1 hour\n",
    "Lack of standard templates, explicit criteria and quick feedback slows generation and evaluation\n",
    "1. AI-powered templates to auto-construct pitches and provide instant feedback for human editing\n",
    "\n",
    "2. Automated evaluation reports and pipelines to expedite committee approval\n",
    "\n",
    "3. Access to platform team experts for direct consultation and recommendations\n",
    "\n",
    "\n",
    "Build AI feature in 6 weeks\n",
    "Setting up infrastructure, experimenting, and applying advanced techniques takes too much time\n",
    "1. Maintain a quick-start list of managed services infrastructure for zero friction project setup and deployment\n",
    "\n",
    "2. Provide an out-of-the-box observability platform for automatic monitoring and evaluations\n",
    "\n",
    "3. Abstract technical infrastructure, design patterns and best practices around advanced features like RAG, Fine Tuning, Agent, Multimodal\n",
    "\n",
    "4. Synthetic data pipelines for bootstrapping teams working with confidential data\n",
    "\n",
    "5. Dedicated platform resources (e.g. engineers, designer) pairing with product teams to accelerate delivery\n",
    "\n",
    "6. Provide UI/UX reviews, advice, starter Figma web components or AI design systems informed by best practices\n",
    "\n",
    "7. Maintain a risk and safety register for the feature informed by AI best practices and frameworks\n",
    "Compliance check in 1 day\n",
    "Staying updated with regulatory frameworks, assessing their impact on product features, and preparing external documents is time-consuming.\n",
    "1. Maintain a searchable, updated compliance directory to track and update local, state, national, and international regulatory frameworks.\n",
    "\n",
    "2. Use RAG-based rubric evaluation for feature compliance\n",
    "\n",
    "3. Automated drafting of approval request letters to appropriate stakeholders\n",
    "GTM in 1 week\n",
    "Lack of marketing resources and inconsistent AI messaging across teams delays launches\n",
    "1. Automate release notes\n",
    "\n",
    "2. Draft user documents pack, including how-to guides and support FAQs\n",
    "\n",
    "3. Generate draft marketing messages, collateral and standard company templates/assets\n",
    "\n",
    "\n",
    "Post-Launch Maintenance for 3 months\n",
    "Maintaining AI features post-launch is resource-intensive, requiring continuous monitoring and a different approach for generative AI's probabilistic nature\n",
    "1. Dedicated hypercare by AI platform team to handle bugs, fixes and updates for 3 months post launch\n",
    "\n",
    "2. Set up automated monitoring systems to track AI performance and detect issues early.\n",
    "\n",
    "3. Providing a BAU service request model for ongoing/complex issues\n",
    "\n",
    "\n",
    "\n",
    "We need a wartime platform squad to stay ahead. Wartime squads move fast, cut red tape, and prioritise impact. They focus on speed and value, driving the company forward by launching AI features quickly. Leaders make tough calls to keep projects on track.\n",
    "This team works seamlessly with product and business teams, enabling them and ruthlessly prioritising the best ideas. They eliminate bureaucracy, integrate new AI tools swiftly, and handle issues head-on. They ensure compliance and safety standards are met without slowing down progress.\n",
    "Unlike peacetime squads that maintain stability, wartime squads thrive in urgency. They deliver immediate results and keep the company ahead of competitors. Quick decisions and a relentless focus on outcomes make them essential for AI leadership and rapid innovation.\n",
    "\"\"\"\n",
    "\n",
    "additional_messages_2 = \"\"\"\n",
    "FAQ\n",
    "**Q:** Do AI platform teams lack the domain knowledge of specific products, making them unsuitable substitutes for product-specific engineering teams?\n",
    "\n",
    "\n",
    "**A:** Yes, AI platform teams lack product-specific knowledge. They're support, not a substitute. To fix this, have the platform team act as a drop-in task force during critical phases, integrating AI while the product squad provides domain expertise. Alternatively, second selected product engineers from a squad to the platform team for a brief period - e.g. six weeks - to share domain knowledge and tailor AI solutions effectively.\n",
    "\n",
    "\n",
    "**Q:** Will the product team be left to maintain the AI system alone after launch?\n",
    "\n",
    "\n",
    "**A:** No. The platform team offers three months of hypercare for bugs and updates. Plus, the product team has access to observability tools to monitor performance and catch issues early. The platform team will also offer a BAU service request model for ongoing/complex issues.\n",
    "\n",
    "\n",
    "**Q:** Will relying on the platform team create bottlenecks and turn them into gatekeepers?\n",
    "\n",
    "\n",
    "**A:** No. The platform team is designed to be an enabler, not a gatekeeper. They prevent bottlenecks by embedding engineers with product teams during critical phases, offering self-service AI tools, and automated processes. The platform team also maintains clear communication and sets SLAs for quick response time. This ensures they support innovation and efficiency, rather than hindering progress.\n",
    "\n",
    "\n",
    "**Q:** Will product engineers miss out on learning AI if platform engineers handle the builds, and will knowledge leave with them?\n",
    "\n",
    "\n",
    "**A:** No. Platform engineers work closely with product teams, provide hands-on training, and keep detailed documentation. Product engineers involved in builds will teach their squad, ensuring everyone learns and retains AI skills.\n",
    "**Q:** If I don't get approved to work with the platform team, does my AI journey end?\n",
    "\n",
    "\n",
    "**A:** No. You can still use self-service tools, resources, and training from the platform team. Product teams keep decision-making autonomy and can build AI features on their own. Approved projects get embedded engineers and time-bound support, but this doesn't remove always-available features or limit reapplying for more support.\n",
    "\n",
    "\n",
    "**Q:** How do you promote equitable access to platform resources across departments and products?\n",
    "**A:** We set clear rules for resource allocation, ensure transparency, and provide self-service tools and training. Open communication helps manage competition, and all teams get equal access. Approved projects get extra support, but everyone can always use available features and reapply for more help.\n",
    "**Q:** How do we measure the platform team's success?\n",
    "\n",
    "\n",
    "**A:** We use practical metrics: time-to-market for AI features, the number of successful AI launches, user feedback, and AI feature funnel conversion from ideas to approved projects. This ensures our efforts provide real benefits to users and improve company results.\n",
    "\n",
    "\n",
    "**Q:** How do we measure the success of the AI features?\n",
    "\n",
    "\n",
    "**A:** The product team tracks user adoption, feedback, performance, and ROI. The platform team helps with tools for monitoring, synthetic data, and risk management. They also provide training, support, and regular reviews to ensure AI features deliver real value and meet business goals.\n",
    "\n",
    "\n",
    "**Q:** What happens if product teams donâ€™t cooperate with the platform team, or vice versa?\n",
    "\n",
    "\n",
    "**A:** The platform team is an optional enabler, offering a range of services as needed. For approved projects with embedded engineers, cooperation is mandatory and ensured through formal agreements endorsed by managers and executives. These agreements include clear requirements, conditions, SLAs, and deliverables, ensuring alignment and accountability, which are critical for achieving company and user outcomes.\n",
    "\n",
    "\n",
    "**Q:** How does the platform team handle both innovation and BAU (Business As Usual) tasks simultaneously?\n",
    "\n",
    "\n",
    "**A:** The platform team manages both by dedicating 70% of their resources to innovation and 30% to BAU tasks. Given the newness of the platform team, this balance might shift as the environment and products mature, allowing for adjustments based on evolving needs and priorities.\n",
    "\n",
    "\n",
    "**Q:** What if the platform team has too many critical projects to work on?\n",
    "\n",
    "\n",
    "**A:** Managers and executives decide which projects to prioritize, based on the platform team's advice. We have a set ratio of resources to projects to manage capacity. This way, the most critical work gets done first.\n",
    "\n",
    "\n",
    "**Q:** What if there's a critical issue post-launch that the product team or platform team can't handle?\n",
    "\n",
    "\n",
    "**A:** We build AI features with feature flags, allowing us to disable them if needed. The platform team maintains a risk and safety register and ensures quick rollback provisions at the code level. If a critical issue arises that the product team or platform team can't manage, we activate existing mechanisms for P1 incidents, including customer communications by senior engineers, managers, and support teams.\n",
    "\n",
    "\n",
    "**Q:** How do we handle the risk of burnout and ensure sustainability if the platform team is constantly working in high-pressure sprints?\n",
    "\n",
    "\n",
    "**A:** The platform team operates in a high-pressure environment with a clear mission to accelerate AI feature launches. To manage burnout, we maintain a 70-30 split between innovation and BAU tasks, and rotate team members between high-intensity projects and less demanding tasks. We recruit team members with this demanding mission in mind from the outset, ensuring they are prepared for the challenges and committed to delivering high performance.\n",
    "\n",
    "\n",
    "**Q:** What happens if there's a V2 feature idea after launch and hypercare?\n",
    "\n",
    "\n",
    "**A:** If a V2 feature idea arises post-launch and hypercare, it goes back through the standard stage gates. For already launched products, we have an accelerated stage gate process. Due to resource limits, product teams can also proceed independently or use a day expertise consultancy model outside of the six-week drop-in period for additional support.\n",
    "\"\"\"\n",
    "\n",
    "additional_messages = [additional_messages_1, additional_messages_2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = wrapper(\n",
    "    system_prompt=faq_system_prompt,\n",
    "    user_prompt=faq_user_prompt,\n",
    "    response_model=Iterable[FAQ],\n",
    "    max_retries=3,\n",
    "    additional_messages=additional_messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 : What is the primary role of the AI platform team in a B2B SaaS company?\n",
      "Answer 1 : The primary role of the AI platform team is to rapidly integrate AI capabilities across the company's products and services, ensure efficient use of AI resources, support product teams, and enable quick time-to-market for AI features.\n",
      "Question 2 : How does the AI platform team prioritize projects?\n",
      "Answer 2 : Project prioritization is based on impact, feasibility, and available resources. Managers and executives make decisions with input from the platform team to ensure the most critical and valuable projects are addressed first.\n",
      "Question 3 : What kind of support does the platform team offer during the prototyping phase?\n",
      "Answer 3 : The platform team provides ready-to-go notebooks, composable components, managed services for quick setup, and optional low/no-code services to help non-engineers prototype rapidly.\n",
      "Question 4 : How does the platform team ensure compliance with AI regulations?\n",
      "Answer 4 : The team maintains an updated compliance directory, uses a RAG-based rubric for evaluations, and automates the drafting of approval request letters to keep up with local, state, national, and international regulatory frameworks.\n",
      "Question 5 : What mechanisms are in place to keep platform team engineers updated with the latest AI advancements?\n",
      "Answer 5 : The platform team ensures continuous learning through regular training sessions, participation in AI conferences, access to AI research publications, and collaboration with industry experts.\n",
      "Question 6 : How does the platform team facilitate collaboration with third-party AI vendors?\n",
      "Answer 6 : The platform team vets and integrates third-party AI services, provides documentation and guidelines for adoption, and works with product teams to ensure seamless integration and value addition.\n",
      "Question 7 : How does the platform team handle data privacy and security concerns?\n",
      "Answer 7 : The team implements strict data privacy protocols, uses synthetic data pipelines for confidential data, maintains a risk and safety register, and ensures compliance with all relevant data protection regulations.\n",
      "Question 8 : In what ways does the platform team accelerate the AI feature development process?\n",
      "Answer 8 : The platform team accelerates the process by providing managed infrastructure, ready-to-use observability tools, quick-start design patterns, dedicated engineering support, and automation of repetitive tasks.\n",
      "Question 9 : How does the AI platform team help business teams automate workflows?\n",
      "Answer 9 : The platform team assists by implementing AI tools for task automation, providing training and resources for using these tools, and ensuring that AI solutions are integrated into existing business processes to improve efficiency.\n",
      "Question 10 : What are the main challenges the platform team might face, and how do they address them?\n",
      "Answer 10 : Key challenges include limited resources, maintaining up-to-date knowledge, and ensuring cross-departmental collaboration. These are addressed through prioritization, continuous learning, clear communication, and formal cooperation agreements.\n",
      "Question 11 : How does the platform team approach risk management for AI features?\n",
      "Answer 11 : Risk management involves maintaining a risk register, implementing feature flags for quick disabling, and setting up rollback procedures. The team also conducts thorough testing and adheres to best practices and frameworks in AI risk management.\n",
      "Question 12 : How do platform teams help managers make data-driven decisions?\n",
      "Answer 12 : The platform team provides robust reporting frameworks, real-time analytics tools, and customized dashboards to help managers track performance, resource allocation, and the impact of AI initiatives.\n",
      "Question 13 : How is the success of the AI platform team incentivized and rewarded?\n",
      "Answer 13 : Success is measured using practical metrics like successful AI launches and user feedback. Rewards may include performance bonuses, public recognition, and career advancement opportunities based on these metrics.\n",
      "Question 14 : What is the role of the AI platform team in shaping organizational culture?\n",
      "Answer 14 : The AI platform team fosters a culture of innovation and responsibility for AI across all levels of the organization, encouraging widespread AI fluency and enthusiasm through training and active collaboration.\n",
      "Question 15 : How does the platform team integrate AI into legacy systems within the company?\n",
      "Answer 15 : The team assesses existing systems, identifies integration points, and uses modular AI components and APIs to ensure seamless integration without major disruptions to the legacy systems.\n",
      "Question 16 : What steps does the platform team take for post-launch support and maintenance of AI features?\n",
      "Answer 16 : Post-launch support includes three months of dedicated hypercare, automated monitoring systems, and a BAU service request model for ongoing and complex issues, ensuring the AI features remain efficient and effective.\n"
     ]
    }
   ],
   "source": [
    "for index, faq in enumerate(response, start=1):\n",
    "    print(f\"Question {index} : {faq.question}\")\n",
    "    print(f\"Answer {index} : {faq.answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
