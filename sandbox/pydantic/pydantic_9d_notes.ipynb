{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal\n",
    "goal = \"Convert a Youtube video transcript or website article into structured notes and diagrams for a local material-mkdocs site.\" # abbreviated to get sections\n",
    "\n",
    "\n",
    "\n",
    "# tasks\n",
    "task_1 = \"Download the complete transcript from the YouTube video.\"\n",
    "# task_2 = \"Collect video metadata (title, author, date) from YouTube.\"\n",
    "# task_3 = \"Identify key topics, keywords and questions from the transcript.\"\n",
    "task_4 = \"Draft an outline with clear sections and subsections based on the concatenated content from the previous tasks.\"\n",
    "task_5 = \"Populate each section and subsection in the outline with detailed content.\"\n",
    "task_6 = \"Create relevant mermaid diagrams and integrate them into the content.\"\n",
    "task_7 = \"Assemble each section into individual Markdown files, including relevant diagrams and metadata.\"\n",
    "task_8 = \"Compile all Markdown files into the material-mkdocs site structure.\"\n",
    "task_9 = \"Launch the local mkdocs site to verify the structure and content.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls\n",
    "\n",
    "url_1 = \"https://www.youtube.com/watch?v=hvAPnpSfSGo\" # langraph\n",
    "url_2 = \"https://www.answer.ai/posts/2024-06-11-os-ai.html\" # Non Youtube AI regulation by Jeremy Howard\n",
    "url_3 = \"https://www.sequoiacap.com/podcast/training-data-harrison-chase/\" # harrison chase on agents\n",
    "url_4 = \"https://www.youtube.com/watch?v=6XZLoW0-mPY\" # harrison chase on agents youtube\n",
    "url_5 = \"https://applied-llms.org/\" # what we learned from a year building with LLMs\n",
    "url_6 = \"https://lithub.com/joan-didion-why-i-write/\" # joan didion\n",
    "url_7 = \"https://www.answer.ai/posts/2023-12-12-launch.html\" # answer ai launch\n",
    "url_8 = \"https://www.youtube.com/watch?v=c0gcsprsFig&t=2839s\" # 3 hour video discussion of what we learned from a year building with LLMs\n",
    "url_8 = \"https://www.youtube.com/watch?v=AwaNygeANFg\" # accelerating AI outerbounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things I want to try\n",
    "\n",
    "- [X] cost decorator\n",
    "- [ ] try different models\n",
    "- [X] exa\n",
    "- [ ] try Surya\n",
    "- [ ] try an audio file and transcriptise it\n",
    "- [ ] a loop where it takes longer than output character limit\n",
    "- [X] style guide with jeremy howard writing or joan dion\n",
    "- [ ] debug mermaid diagrams in launch\n",
    "- [ ] debug sequencing of filesplit in launch\n",
    "- [ ] debug title, description and formatting in launch\n",
    "- [ ] figure out a way to use router to launch it\n",
    "- [ X] make an exa tool or just an llm call to get the stripped down text?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import enum\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from exa_py import Exa\n",
    "from googleapiclient.discovery import build\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "from pydantic import BaseModel, Field, StringConstraints, UUID4, conlist, constr, field_validator\n",
    "import requests\n",
    "import tiktoken\n",
    "import time\n",
    "from typing import Any, Callable, ClassVar, Dict, Iterable, List, Optional, Type, Union\n",
    "from typing_extensions import Annotated, Literal\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter, TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "\n",
    "dotenv_path = Path(r\"C:\\Storage\\python_projects\\ashvin\\.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "EXA_API_KEY = os.getenv(\"EXA_API_KEY\")\n",
    "\n",
    "# main constants\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\" # points to latest GPT model\n",
    "URL = url_8\n",
    "\n",
    "#instantiate client\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.TOOLS)\n",
    "audio_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost decorator\n",
    "\n",
    "class CostDetails(BaseModel):\n",
    "    input_cost: float\n",
    "    output_cost: float\n",
    "    total_cost: float\n",
    "\n",
    "    def formatted_input_cost(self):\n",
    "        return f\"${self.input_cost:.6f}\"\n",
    "\n",
    "    def formatted_output_cost(self):\n",
    "        return f\"${self.output_cost:.6f}\"\n",
    "\n",
    "    def formatted_total_cost(self):\n",
    "        return f\"${self.total_cost:.6f}\"\n",
    "\n",
    "def cost(function: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator to calculate and add the cost of token usage based on predefined model pricing.\n",
    "    \n",
    "    This decorator enriches the output of the decorated function by calculating the cost\n",
    "    based on the number of prompt and completion tokens used. The costs are computed\n",
    "    according to a hardcoded pricing table for supported models.\n",
    "\n",
    "    Args:\n",
    "        function (Callable): The function to be decorated, expected to return an instance\n",
    "                             of a model with token counts included.\n",
    "\n",
    "    Returns:\n",
    "        Callable: A decorator that enhances the function's output with cost calculations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the pricing table within the decorator\n",
    "    pricing = {\n",
    "        'gpt-4o': {\n",
    "            'input': 5.00 / 1000000,  # $5.00 per 1M tokens\n",
    "            'output': 15.00 / 1000000  # $15.00 per 1M tokens\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def decorated_function(*args, **kwargs) -> Any:\n",
    "        # Call the original function and capture its output\n",
    "        result = function(*args, **kwargs)\n",
    "        \n",
    "        # Extract token counts using dot notation\n",
    "        prompt_tokens = result.token_counts.prompt_tokens\n",
    "        completion_tokens = result.token_counts.completion_tokens\n",
    "\n",
    "        # Determine the model used; default to 'gpt-4o' for now\n",
    "        model = 'gpt-4o'  # This could be dynamically determined based on args/kwargs if needed\n",
    "\n",
    "        # Calculate costs based on the price table for the specific model\n",
    "        input_cost = prompt_tokens * pricing[model]['input']\n",
    "        output_cost = completion_tokens * pricing[model]['output']\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        # Assign cost details using the CostDetails model\n",
    "        result.cost_details = CostDetails(\n",
    "            input_cost=input_cost,\n",
    "            output_cost=output_cost,\n",
    "            total_cost=total_cost\n",
    "        )\n",
    "\n",
    "        # Optionally print formatted cost details for transparency\n",
    "        print(f\"Cost Details: Input: {result.cost_details.formatted_input_cost()}, Output: {result.cost_details.formatted_output_cost()}, Total: {result.cost_details.formatted_total_cost()}\")\n",
    "        return result\n",
    "\n",
    "    return decorated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "\n",
    "@cost\n",
    "def wrapper(\n",
    "    system_prompt: str | None = None, \n",
    "    user_prompt: Union[str, List[str]] | None = None, \n",
    "    response_model: BaseModel | None = None, \n",
    "    max_retries: int = 3, \n",
    "    additional_messages: Union[str, List[str]] | None = None\n",
    ") -> 'WrapperOutput':\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates LLM completions using provided parameters and collects token usage information.\n",
    "    \n",
    "    This function dynamically constructs a message array for the LLM based on input parameters,\n",
    "    handles the completion process using either standard or model-based completions depending on \n",
    "    the presence of a response model, and returns structured outputs including both the completion \n",
    "    response and token usage statistics.\n",
    "\n",
    "    Args:\n",
    "        system_prompt (str, optional): System-level initial prompt or instruction.\n",
    "        user_prompt (Union[str, List[str]], optional): User-provided content or context as a single string or list of strings.\n",
    "        response_model (BaseModel, optional): Pydantic model to structure the response when using model-specific completions.\n",
    "        max_retries (int): Maximum number of retries for the LLM request.\n",
    "        additional_messages (Union[str, List[str]], optional): Additional messages to precede the user prompt.\n",
    "\n",
    "    Returns:\n",
    "        WrapperOutput: A Pydantic model containing the LLM response and detailed token counts.\n",
    "\n",
    "    Classes Defined Inside:\n",
    "        TokenCounts: A Pydantic model detailing the counts of different types of tokens.\n",
    "        WrapperOutput: A Pydantic model encapsulating the response and TokenCounts model.\n",
    "    \"\"\"\n",
    "\n",
    "    class TokenCounts(BaseModel):\n",
    "        completion_tokens: int\n",
    "        prompt_tokens: int\n",
    "        total_tokens: int\n",
    "\n",
    "    class WrapperOutput(BaseModel):\n",
    "        response: Union[str, BaseModel]\n",
    "        token_counts: TokenCounts\n",
    "        cost_details: Optional[Dict[str, str]] = None\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    # Construct the messages list based on provided inputs\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    if additional_messages:\n",
    "        # Can handle both list of messages or a single string\n",
    "        if isinstance(additional_messages, List):\n",
    "            messages.extend([{\"role\": \"user\", \"content\": message} for message in additional_messages])\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": additional_messages})\n",
    "\n",
    "    if user_prompt:\n",
    "        # Similarly, handles both single and multiple user prompts\n",
    "        if isinstance(user_prompt, List):\n",
    "            messages.extend([{\"role\": \"user\", \"content\": context} for context in user_prompt])\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Generate the completion and extract token counts based on the presence of a response model\n",
    "    if response_model is None:\n",
    "        # Standard completion process without a structured model\n",
    "        completion = client.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            response_model=None,\n",
    "            max_retries=max_retries,\n",
    "            messages=messages\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content.strip()\n",
    "        token_counts = TokenCounts(\n",
    "            completion_tokens=completion.usage.completion_tokens,\n",
    "            prompt_tokens=completion.usage.prompt_tokens,\n",
    "            total_tokens=completion.usage.total_tokens\n",
    "        )\n",
    "    else:\n",
    "        # Model-based completion that structures the response as per the specified BaseModel\n",
    "        structured_response, raw_completion = client.chat.completions.create_with_completion(\n",
    "            model=GPT_MODEL,\n",
    "            response_model=response_model,\n",
    "            max_retries=max_retries,\n",
    "            messages=messages\n",
    "        )\n",
    "        response_content = structured_response\n",
    "        token_counts = TokenCounts(\n",
    "            completion_tokens=raw_completion.usage.completion_tokens,\n",
    "            prompt_tokens=raw_completion.usage.prompt_tokens,\n",
    "            total_tokens=raw_completion.usage.total_tokens\n",
    "        )\n",
    "\n",
    "    return WrapperOutput(response=response_content, token_counts=token_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict tokens\n",
    "\n",
    "def count_tokens(text: str, print_length: bool = True, token_type: str = 'input') -> int:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a given text string using a specific tokenization model, print the token count,\n",
    "    calculate and print the cost of tokens based on a pricing table.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text string to tokenize and count.\n",
    "        print_length (bool): If True, prints the length of the tokens. Default is True.\n",
    "        token_type (str): Specifies whether to use 'input' or 'output' token pricing. Default is 'input'.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens in the text.\n",
    "    \"\"\"\n",
    "    # Encode the transcript to count tokens\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    token_count = len(tokens)\n",
    "\n",
    "    # Print the token length if required\n",
    "    if print_length:\n",
    "        print(f\"Token count: {token_count}\")\n",
    "\n",
    "    # Pricing table\n",
    "    pricing = {\n",
    "        'input': 5 / 1_000_000,  # $5 per 1 million tokens\n",
    "        'output': 15 / 1_000_000  # $15 per 1 million tokens\n",
    "    }\n",
    "\n",
    "    # Calculate and print cost\n",
    "    cost = pricing[token_type] * token_count\n",
    "    print(f\"Cost for {token_type} tokens: ${cost:.6f}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube video metadata tool\n",
    "# requires youtube API key\n",
    "\n",
    "class YoutubeDetails(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the YouTube video ID from a given URL, retrieves key metadata,\n",
    "    and formats it as a dictionary.\n",
    "    \n",
    "    The metadata extracted includes:\n",
    "        - Title: The title of the video.\n",
    "        - Description: The description of the video.\n",
    "        - Published At: The date and time when the video was published.\n",
    "        - Channel Title: The title of the channel that uploaded the video.\n",
    "        - Views: The number of views the video has received.\n",
    "        - Likes: The number of likes the video has received.\n",
    "        - Dislikes: The number of dislikes the video has received.\n",
    "        - Comments: The number of comments on the video.\n",
    "        - Duration: The duration of the video in ISO 8601 format.\n",
    "        - Tags: A list of tags associated with the video.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str) -> Optional[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Extract the YouTube video ID from a given URL, retrieve key metadata,\n",
    "        and format it as a dictionary.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The YouTube URL from which to extract the video ID.\n",
    "\n",
    "        Returns:\n",
    "            Optional[Dict[str, str]]: The video metadata if the video ID is valid and the\n",
    "                                      metadata is available, otherwise None.\n",
    "        \"\"\"\n",
    "        # Regular expression to find the video ID in a YouTube URL\n",
    "        pattern = r'(?:https?://)?(?:www\\.)?(?:youtube\\.com/watch\\?v=|youtu\\.be/)([a-zA-Z0-9_-]{11})'\n",
    "        match = re.search(pattern, url)\n",
    "        if not match:\n",
    "            print(\"No valid YouTube video ID found in the provided URL.\")\n",
    "            return None\n",
    "\n",
    "        video_id = match.group(1)\n",
    "\n",
    "        try:\n",
    "            if not YOUTUBE_API_KEY:\n",
    "                print(\"API key not found in environment variables.\")\n",
    "                return None\n",
    "\n",
    "            youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)\n",
    "            request = youtube.videos().list(part='snippet,contentDetails,statistics', id=video_id)\n",
    "            response = request.execute()\n",
    "\n",
    "            if not response['items']:\n",
    "                print(\"No video found with the provided video ID.\")\n",
    "                return None\n",
    "\n",
    "            video_details = response['items'][0]\n",
    "            metadata = {\n",
    "                \"Title\": video_details['snippet']['title'],\n",
    "                \"Description\": video_details['snippet']['description'],\n",
    "                \"Published At\": video_details['snippet']['publishedAt'],\n",
    "                \"Channel Title\": video_details['snippet']['channelTitle'],\n",
    "                \"Views\": video_details['statistics'].get('viewCount', 'N/A'),\n",
    "                \"Likes\": video_details['statistics'].get('likeCount', 'N/A'),\n",
    "                \"Dislikes\": video_details['statistics'].get('dislikeCount', 'N/A'),\n",
    "                \"Comments\": video_details['statistics'].get('commentCount', 'N/A'),\n",
    "                \"Duration\": video_details['contentDetails']['duration'],\n",
    "                \"Tags\": video_details['snippet'].get('tags', [])\n",
    "            }\n",
    "\n",
    "            return metadata\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving video metadata: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript from youtube video tool\n",
    "\n",
    "class Transcript(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the YouTube video ID from a given URL, retrieves the transcript, and \n",
    "    formats it as a JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract the YouTube video ID from a given URL, retrieve the transcript,\n",
    "        and format it as a JSON string.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The YouTube URL from which to extract the video ID.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The JSON formatted transcript if the video ID is valid and the\n",
    "                           transcript is available, otherwise None.\n",
    "        \"\"\"\n",
    "        # Regular expression to find the video ID in a YouTube URL\n",
    "        pattern = r'(?:https?://)?(?:www\\.)?youtube\\.com/watch\\?v=([a-zA-Z0-9_-]{11})'\n",
    "        match = re.search(pattern, url)\n",
    "        if not match:\n",
    "            print(\"No valid YouTube video ID found in the provided URL.\")\n",
    "            return None\n",
    "\n",
    "        video_id = match.group(1)\n",
    "\n",
    "        try:\n",
    "            # Retrieve the transcript\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en-GB', 'en'])\n",
    "\n",
    "            # Format the transcript as JSON\n",
    "            formatter = JSONFormatter()\n",
    "            json_formatted_transcript = formatter.format_transcript(transcript)\n",
    "\n",
    "            return json_formatted_transcript\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving or formatting transcript: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract metadata from text\n",
    "\n",
    "class MetaData(BaseModel):\n",
    "    \"\"\"\n",
    "    Extract various metadata properties from a text - PrimarySource - and generate a MetaData instance by processing the text.\n",
    "    Each property is described by a specific prompt, and this class can generate and return a metadata report\n",
    "    based on the input text.\n",
    "    \"\"\"\n",
    "\n",
    "    documentation_names: conlist(constr(max_length=100), min_length=1, max_length=10) = Field(\n",
    "        default=None,\n",
    "        description=\"Generate up to 10 possible names for documentation we want to build, for the data in PrimarySource.\",\n",
    "        example=[\"Documentation1\", \"Guide\", \"Manual\"]\n",
    "    )\n",
    "\n",
    "    intended_audience: conlist(constr(max_length=100), min_length=1, max_length=10) = Field(\n",
    "        default=None,\n",
    "        description=\"Generate up to 10 words describing the intended audience for creating documentation from the data in PrimarySource.\",\n",
    "        example=[\"Beginners\", \"Advanced Users\", \"Developers\", \"Managers\"]\n",
    "    )\n",
    "\n",
    "    description: constr(max_length=500) = Field(\n",
    "        default=None,\n",
    "        description=\"Provide a three-sentence description of the information in PrimarySource.\",\n",
    "        example=\"This is an article about data science best practices.\"\n",
    "    )\n",
    "\n",
    "    keywords: conlist(constr(max_length=50), min_length=1, max_length=10) = Field(\n",
    "        default=None,\n",
    "        description=\"Generate up to 10 possible keywords referring to industries, technologies, people or other themes for the data in PrimarySource.\",\n",
    "        example=[\"Data Science\", \"Machine Learning\"]\n",
    "    )\n",
    "\n",
    "    clarification_questions: conlist(constr(max_length=200), min_length=1, max_length=10) = Field(\n",
    "    default=None,\n",
    "    description=\"Generate a list of insightful questions that target ambiguities or complex areas within PrimarySource, prompting deeper exploration or explanation.\",\n",
    "    example=[\n",
    "        \"Can you explain the significance of the statistical methods used in this analysis?\",\n",
    "        \"What are the implications of these findings for the broader field of study?\",\n",
    "        \"How does this information compare with prior established studies?\",\n",
    "        \"What methodologies were used in the data collection process?\",\n",
    "        \"Could you detail the reasoning behind the conclusions drawn in this document?\",\n",
    "        \"What are the potential biases in this study, and how were they addressed?\",\n",
    "        \"Can you clarify the terms used in the discussion of the results?\",\n",
    "        \"Are there any assumptions in this study that need more detailed justification?\",\n",
    "        \"What are the limitations of this study, and how do they affect the results?\",\n",
    "        \"How can the findings be applied in practical scenarios?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "    def run(self, text: str) -> 'MetaData':\n",
    "        \"\"\"\n",
    "        Process the input text to extract metadata and generate a MetaData instance.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text from which to extract metadata.\n",
    "\n",
    "        Returns:\n",
    "            MetaData: An instance of MetaData class filled with extracted metadata.\n",
    "        \"\"\"\n",
    "\n",
    "        metadata = wrapper(\n",
    "            system_prompt=\"Extract metadata from the provided text.\",\n",
    "            user_prompt=text,\n",
    "            response_model=MetaData,  # Assuming the wrapper can fill a MetaData instance\n",
    "            max_retries=3\n",
    "        )\n",
    "\n",
    "        return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outline as a knowledge graph tool\n",
    "\n",
    "class OutlineNode(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a node in the outline. Each node can represent a section or a subsection.\n",
    "\n",
    "    Attributes:\n",
    "        id (int): Unique identifier for the node.\n",
    "        title (str): Title of the node.\n",
    "        description (str): A single sentence description of the node.\n",
    "        key_points (List[str]): A list of very short strings outlining key points to cover in this node.\n",
    "        parent_id (Union[int, None]): Identifier of the parent node, if any.\n",
    "    \"\"\"\n",
    "    id: int = Field(None, description=\"Unique identifier for the node.\")\n",
    "    title: str = Field(None, description=\"Title of the node.\")\n",
    "    description: str = Field(None, description=\"A single sentence description of the node.\")\n",
    "    key_points: List[str] = Field(default_factory=list, description=\"A list of very short strings outlining key points to cover in this node.\")\n",
    "    parent_id: Union[int, None] = Field(default=None, description=\"Identifier of the parent node, if any.\")\n",
    "\n",
    "\n",
    "class OutlineEdge(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents an edge in the outline, connecting two nodes.\n",
    "\n",
    "    Attributes:\n",
    "        source (int): Identifier of the source node.\n",
    "        target (int): Identifier of the target node.\n",
    "        label (str): Label describing the relationship between the nodes. Be expressive and precise in label selection.\n",
    "    \"\"\"\n",
    "    source: int = Field(None, description=\"Identifier of the source node.\")\n",
    "    target: int = Field(None, description=\"Identifier of the target node.\")\n",
    "    label: str = Field(None, description=\"Label describing the relationship between the nodes.Be expressive and precise in label selection.\")\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the overall structure of a document outline, containing multiple nodes and edges.\n",
    "\n",
    "    The outline can have sections, subsections, and subsubsections. A section can have many subsections,\n",
    "    and each subsection can have many subsubsections. Ideally the first section doesn't have any subsections.\n",
    "    The levels of nestedness are limited to a maximum of three levels:\n",
    "        - Level 1: Section - corresponds to ## in markdown\n",
    "        - Level 2: Subsection - corresponds to ### in markdown\n",
    "        - Level 3: Subsubsection - corresponds to #### in markdown\n",
    "\n",
    "    Attributes:\n",
    "        title (str): Title of the document for which the outline is generated.\n",
    "        nodes (List[OutlineNode]): List of nodes in the document outline.\n",
    "        edges (List[OutlineEdge]): List of edges connecting the nodes in the document outline.\n",
    "    \"\"\"\n",
    "    title: str = Field(None, description=\"Title of the document for which the outline is generated.\")\n",
    "    nodes: List[OutlineNode] = Field(default_factory=list, description=\"List of nodes in the document outline.\")\n",
    "    edges: List[OutlineEdge] = Field(default_factory=list, description=\"List of edges connecting the nodes in the document outline.\")\n",
    "\n",
    "    def run(self, text: str) -> 'Outline':\n",
    "        \"\"\"\n",
    "        Generate an outline based on the input text.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text to generate the outline from.\n",
    "\n",
    "        Returns:\n",
    "            Outline: An instance of the Outline class with the generated outline.\n",
    "        \"\"\"\n",
    "        outline = wrapper(\n",
    "            system_prompt=\"\"\"\n",
    "            Generate a detailed, structured outline of the document based on the provided text.\n",
    "            The outline should have appropriate sections, subsections and subsubsections.\n",
    "            Ideally the first section doesn't have any subsections.\n",
    "            \"\"\",\n",
    "            user_prompt=text,\n",
    "            response_model=Outline,\n",
    "            max_retries=3\n",
    "        )\n",
    "        return outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web text extraction tool\n",
    "\n",
    "class WebTextExtractor(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the text content from a given URL using the requests module.\n",
    "    \n",
    "    The extracted text can include the raw HTML content or just the text content of the web page.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str, return_html: bool = False) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract the text content from a given URL.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The URL from which to extract the text content.\n",
    "            return_html (bool): If True, return the full HTML content. If False, return plain text. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The text content of the web page if the request is successful,\n",
    "                           otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "            \n",
    "            if return_html:\n",
    "                return response.text\n",
    "            else:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                page_text = soup.get_text()\n",
    "                return page_text.strip()\n",
    "                \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching the web page: {e}\")\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing style guide\n",
    "\n",
    "class WritingStyleGuide(BaseModel):\n",
    "    \"\"\"\n",
    "    A comprehensive writing style guide encompassing grammar, sentences, paragraphs, tone of voice, precision, and overall quality. This guide helps in capturing a unique tone of voice and approach.\n",
    "    \"\"\"\n",
    "\n",
    "    target_audience: List[constr(min_length=1, max_length=100)] = Field(\n",
    "        None,\n",
    "        description=\"Specify up to 5 target audiences, and why they are the target. This guides the tone and complexity.\",\n",
    "        max_items=5,\n",
    "        examples=[\"General Public: Need straightforward explanations\", \"Technical Experts: Require detailed and precise information\"]\n",
    "    )\n",
    "\n",
    "    tone: constr(min_length=1, max_length=100) = Field(\n",
    "        None,\n",
    "        description=\"The tone of your writing, such as formal, informal, conversational, or authoritative. Adapt the tone based on the target audience.\",\n",
    "        examples=[\"Conversational for general public, formal for technical experts\"]\n",
    "    )\n",
    "\n",
    "    grammar_rules: List[constr(min_length=1, max_length=100)] = Field(\n",
    "        None,\n",
    "        description=\"Key grammar rules to follow. Avoid common pitfalls like passive voice and excessive adverbs.\",\n",
    "        max_items=10,\n",
    "        examples=[\"Use active voice\", \"Avoid passive constructions\", \"Use the Oxford comma\", \"Limit the use of adverbs\"]\n",
    "    )\n",
    "\n",
    "    sentence_structure: constr(min_length=1, max_length=200) = Field(\n",
    "        None,\n",
    "        description=\"Guidelines for sentence structure. Use short, direct sentences but vary length to create rhythm.\",\n",
    "        examples=[\"Use short, direct sentences. Keep most sentences between 10-15 words. Vary sentence length for rhythm.\"]\n",
    "    )\n",
    "\n",
    "    paragraph_structure: constr(min_length=1, max_length=200) = Field(\n",
    "        None,\n",
    "        description=\"Guidelines for paragraph structure. Ensure logical flow and coherence within paragraphs.\",\n",
    "        examples=[\"Begin with a topic sentence. Follow with supporting sentences. End with a concluding sentence. Ensure each paragraph has a single clear idea.\"]\n",
    "    )\n",
    "\n",
    "    preferred_words: List[constr(min_length=1, max_length=50)] = Field(\n",
    "        None,\n",
    "        description=\"Extract or infer up to 10 concrete words or phrases to use often. Avoid jargon and tired tropes.\",\n",
    "        max_items=10,\n",
    "        examples=[\"Clear\", \"Direct\", \"Simple\", \"Precise\"]\n",
    "    )\n",
    "\n",
    "    avoid_words: List[constr(min_length=1, max_length=50)] = Field(\n",
    "        None,\n",
    "        description=\"Extract or infer up to 10 words or phrases to avoid. Explain why these should be avoided.\",\n",
    "        max_items=10,\n",
    "        examples=[\"Leverage: overused business jargon\", \"Utilize: 'use' is simpler\", \"Cutting-edge: vague and cliché\"]\n",
    "    )\n",
    "\n",
    "    formatting: constr(min_length=1, max_length=500) = Field(\n",
    "        None,\n",
    "        description=\"Formatting guidelines to ensure consistency and readability. Include headings, bullet points, and emphasis.\",\n",
    "        examples=[\"Use H2 for section titles, bullet points for lists, and italics for emphasis. Ensure consistent formatting throughout the document.\"]\n",
    "    )\n",
    "\n",
    "    citation_style: constr(min_length=1, max_length=100) = Field(\n",
    "        None,\n",
    "        description=\"The preferred citation style, such as APA, MLA. Provide examples of correct citation formats.\",\n",
    "        examples=[\"APA: (Author, Year). MLA: (Author Page).\"]\n",
    "    )\n",
    "\n",
    "    common_phrases: List[constr(min_length=1, max_length=100)] = Field(\n",
    "        None,\n",
    "        description=\"Up to 10 common phrases to ensure consistency. Use these to link ideas smoothly.\",\n",
    "        max_items=10,\n",
    "        examples=[\"In short\", \"To sum up\", \"Moreover\", \"Furthermore\"]\n",
    "    )\n",
    "\n",
    "    precision: constr(min_length=1, max_length=200) = Field(\n",
    "        None,\n",
    "        description=\"Guidelines for ensuring precision in writing. Provide tips on how to achieve it.\",\n",
    "        examples=[\"Use specific, concrete language. Avoid vague terms. Double-check facts and figures. Provide examples when possible.\"]\n",
    "    )\n",
    "\n",
    "    clarity: constr(min_length=1, max_length=200) = Field(\n",
    "        None,\n",
    "        description=\"Guidelines for maintaining clarity. Provide examples of clear vs. unclear sentences.\",\n",
    "        examples=[\"Ensure each sentence conveys a single idea clearly. Unclear: 'The report, which was long and detailed, was not read by the committee.' Clear: 'The committee did not read the long, detailed report.'\"]\n",
    "    )\n",
    "\n",
    "    readability: constr(min_length=1, max_length=200) = Field(\n",
    "        None,\n",
    "        description=\"Guidelines for ensuring readability. Avoid jargon and overly complex words.\",\n",
    "        examples=[\"Use simple words and phrases. Avoid technical jargon unless necessary. Break up long paragraphs. Use transitional phrases between ideas.\"]\n",
    "    )\n",
    "\n",
    "    emotional_connection: Optional[constr(max_length=200)] = Field(\n",
    "        None,\n",
    "        description=\"Ensure the writing connects with readers on an emotional and intellectual level.\",\n",
    "        examples=[\"Use personal anecdotes and reflections to engage readers emotionally. Address the reader directly when appropriate.\"]\n",
    "    )\n",
    "\n",
    "    sensory_details: Optional[constr(max_length=200)] = Field(\n",
    "        None,\n",
    "        description=\"Incorporate sensory details to make the writing vivid and engaging.\",\n",
    "        examples=[\"Describe scenes with details that appeal to the senses, such as sights, sounds, and smells. Use metaphors and similes to create vivid imagery.\"]\n",
    "    )\n",
    "\n",
    "    honesty_integrity: constr(min_length=1, max_length=200) = Field(\n",
    "        None,\n",
    "        description=\"Emphasize the importance of honesty and integrity in writing.\",\n",
    "        examples=[\"Always present facts accurately and acknowledge sources. Be transparent about any biases. Correct errors promptly and openly.\"]\n",
    "    )\n",
    "\n",
    "    def create(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate a report summarizing the writing style guide.\n",
    "\n",
    "        Returns:\n",
    "            str: A summary of the writing style guide.\n",
    "        \"\"\"\n",
    "        report = [\n",
    "            \"Writing Style Guide Summary:\",\n",
    "            f\"\\nTarget Audience:\",\n",
    "            *[f\"- {audience}\" for audience in self.target_audience or []],\n",
    "            f\"\\nTone: {self.tone}\",\n",
    "            f\"\\nGrammar Rules:\",\n",
    "            *[f\"- {rule}\" for rule in self.grammar_rules or []],\n",
    "            f\"\\nSentence Structure: {self.sentence_structure}\",\n",
    "            f\"\\nParagraph Structure: {self.paragraph_structure}\",\n",
    "            f\"\\nPreferred Words: {', '.join(self.preferred_words or [])}\",\n",
    "            f\"\\nWords to Avoid:\",\n",
    "            *[f\"- {word}\" for word in self.avoid_words or []],\n",
    "            f\"\\nFormatting: {self.formatting}\",\n",
    "            f\"\\nCitation Style: {self.citation_style}\",\n",
    "            f\"\\nCommon Phrases: {', '.join(self.common_phrases or [])}\",\n",
    "            f\"\\nPrecision: {self.precision}\",\n",
    "            f\"\\nClarity: {self.clarity}\",\n",
    "            f\"\\nReadability: {self.readability}\",\n",
    "            f\"\\nHonesty and Integrity: {self.honesty_integrity}\"\n",
    "        ]\n",
    "        \n",
    "        if self.emotional_connection:\n",
    "            report.append(f\"\\nEmotional Connection: {self.emotional_connection}\")\n",
    "        \n",
    "        if self.sensory_details:\n",
    "            report.append(f\"\\nSensory Details: {self.sensory_details}\")\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "    def run(self, text: str | None = None) -> str:\n",
    "        \"\"\"\n",
    "        Generate a writing style guide based on the provided text using an LLM.\n",
    "\n",
    "        Parameters:\n",
    "            text (str): The input text to generate the writing style guide from.\n",
    "\n",
    "        Returns:\n",
    "            str: A JSON representation of the WritingStyleGuide instance.\n",
    "        \"\"\"\n",
    "        instance = wrapper(\n",
    "            system_prompt=\"\"\"\n",
    "            Extract or infer a comprehensive writing style guide with all relevant properties based on the provided text. \n",
    "            This guide should help in capturing a unique tone of voice and approach based on the provided text.\n",
    "            \"\"\",\n",
    "            user_prompt=text,\n",
    "            response_model=WritingStyleGuide,\n",
    "            max_retries=3\n",
    "        )\n",
    "        return instance.response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section tools\n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    description: str\n",
    "    key_points: List[str]\n",
    "    content: Optional[str] = None  # Detailed content in Markdown or plain text\n",
    "\n",
    "class Section(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "    description: str\n",
    "    key_points: List[str]\n",
    "    subsections: List[Subsection] = []\n",
    "    content: Optional[str] = None  # Detailed content in Markdown or plain text\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Run for Writing Style Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get text from website incl html\n",
    "\n",
    "web_text_extraction_tool = WebTextExtractor()\n",
    "web_text_1 = web_text_extraction_tool.run(url_1)\n",
    "web_text_2 = web_text_extraction_tool.run(url_7)\n",
    "web_text_3 = web_text_1 + web_text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_guide_tool = WritingStyleGuide()\n",
    "style_guide = style_guide_tool.run(web_text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(style_guide.create())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = wrapper(\n",
    "    system_prompt = f\"\"\"Write me an essay about learning to build in and with AI after 40 without a strong tech background. \n",
    "    Constantly feeling like an imposter but trying to inch forward.\n",
    "    Follow the style of : {web_text_3}.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(essay.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_story = wrapper(\n",
    "    system_prompt = f\"\"\"\n",
    "    Revise the provided short story about nanomachines using this style guide to improve the prose and content : {style_guide.create()}.\n",
    "    Always favour simple words and jargon free prose. Meaning should shine through simplicity and precision of prose and content choices. \n",
    "    Remember it is a story not a report. The writing should flow. No bullet points.\n",
    "    \"\"\",\n",
    "    user_prompt = short_story.response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_story.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 19107\n",
      "Cost for input tokens: $0.095535\n"
     ]
    }
   ],
   "source": [
    "# get text from youtube video\n",
    "\n",
    "transcript_tool = Transcript()\n",
    "transcript = transcript_tool.run(url_1)\n",
    "_ = count_tokens(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.097795, Output: $0.009825, Total: $0.107620\n"
     ]
    }
   ],
   "source": [
    "# get schema from webtext and transcript\n",
    "\n",
    "outline_tool = Outline()\n",
    "outline = outline_tool.run(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.004245, Output: $0.006960, Total: $0.011205\n"
     ]
    }
   ],
   "source": [
    "sections = wrapper(\n",
    "    system_prompt = \"Given this knowledge graph, extract the detailed outline for sections and subsections. Do not fill in the content.\",\n",
    "    user_prompt = outline.response.model_dump_json(),\n",
    "    response_model = Sections\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sections(sections=[Section(id=1, title='Introduction', description='Introduction to LangGraph and its purpose', key_points=['Overview', 'Purpose of LangGraph'], subsections=[], content=None), Section(id=2, title='LangGraph Overview', description='Detailed introduction to LangGraph and its functionalities', key_points=['Definition of LangGraph', 'Similarities with NetworkX', 'Syntax and basic structure'], subsections=[], content=None), Section(id=3, title='Multi-Agent Workflows', description='Different types of multi-agent workflows that can be created using LangGraph', key_points=['Definition of agent-like workflows', 'Definition of cycles', 'Comparison with state machines', 'Nodes and edges in LangGraph'], subsections=[Subsection(id=4, title='Multi-Agent Collaboration', description='Casting multi-agent collaboration using LangGraph', key_points=['Shared state among agents', 'Example of researcher agent and chart generator'], content=None), Subsection(id=6, title='Agent Supervision', description='Detailed explanation of the agent supervisor model', key_points=['Independent agents', 'Role of supervisor', 'Routing between agents'], content=None), Subsection(id=8, title='Hierarchical Agent Team', description='Introduction and explanation of hierarchical agent team model', key_points=['Difference from multi-agent collaboration and agent supervision', 'Components of hierarchical agent team'], content=None)], content=None), Section(id=10, title='Conclusion', description='Summary and final thoughts on creating multi-agent workflows using LangGraph', key_points=['Benefits of multi-agent workflows', 'Applications and future scope'], subsections=[], content=None)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = f\"\"\"\n",
    "This is the primary source : {web_text}\n",
    "---\n",
    "\n",
    "This is extracted metadata about the primary source : {metadata.response.model_dump_json()}\n",
    "\n",
    "---\n",
    "This is the outline of notes about the primary source expressed as a knowledge graph of nodes and edges : {outline_webtext.response.model_dump_json()}\n",
    "\n",
    "---\n",
    "Task 1 :\n",
    "\n",
    "Given this knowledge graph, extract the outline in markdown with appropriate formatting for sections and subsections\n",
    "\n",
    "---\n",
    "\n",
    "Task 2 : \n",
    "\n",
    "Follow the structure established in the outline, extract and then infer the content from the primary source, the extracted metadata and your knowledge.\n",
    "For each section or subsection fill in the content in extensive and precise detail.\n",
    "Write in markdown, with appropriate formatting (bold, italics, headings, bullet points, etc).\n",
    "Write it as an expert in the themes.\n",
    "\n",
    "---\n",
    "ONLY RETURN THE OUTPUT FROM TASK 2. DO NOT ENCLOSE THE OUTPUT IN CODE BLOCKS.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = wrapper(\n",
    "    user_prompt = task,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_task = f\"\"\"\n",
    "This is the primary source : {web_text}\n",
    "\n",
    "---\n",
    "This is the initial draft of detailed and structured notes extracted from the transcript: {content.response}\n",
    "\n",
    "---\n",
    "Task:\n",
    "\n",
    "Preserve the markdown structure of the initial draft.\n",
    "Extend, update and revise the content of each section and subsection to:\n",
    "    - provide more detail to each section and subsection by incorporating relevant information from the primary source\n",
    "    - selectively incorporate callouts where appropriate. Use direct quotes in callouts where appropriate.\n",
    "    - The added detail is of the same writing clarity and quality as previously. \n",
    "Extend the content by selectively incorporating one or more mermaid diagrams:\n",
    "    - Only insert mermaid diagrams where appropriate so that the reader can better understand the note content\n",
    "    - Extract or infer details for the diagrams from primary source or the revised draft\n",
    "    - Insert the diagram in code blocks at the appropriate section, subsection or subsubsection of the revised draft\n",
    "    - The diagrams should be accessible and easy to grasp. They should not be overly complex or complicated.\n",
    "Return a revised set of notes in markdown with the appropriately inserted mermaid diagram code\n",
    "\n",
    "---\n",
    "ONLY RETURN THE OUTPUT FROM THE TASK. DO NOT ENCLOSE THE OUTPUT IN CODE BLOCKS.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = wrapper(\n",
    "    user_prompt = new_task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (you may need to run this in a separate cell)\n",
    "!pip install mkdocs mkdocs-material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdocs code\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def split_markdown(content):\n",
    "    \"\"\"\n",
    "    Split the markdown content into separate files based on headers.\n",
    "    \n",
    "    Args:\n",
    "    content (str): The full markdown content.\n",
    "    \n",
    "    Returns:\n",
    "    list of tuples: Each tuple contains (filename, content) for each section.\n",
    "    \"\"\"\n",
    "    print(\"Splitting markdown...\")\n",
    "    # Split on both # and ## to catch all sections\n",
    "    sections = re.split(r'^(#|##)\\s', content, flags=re.MULTILINE)\n",
    "    files = []\n",
    "    current_file = 'index.md'\n",
    "    current_content = []\n",
    "\n",
    "    for i, section in enumerate(sections):\n",
    "        if section in ['#', '##']:\n",
    "            if current_content:\n",
    "                files.append((current_file, ''.join(current_content).strip()))\n",
    "                current_content = []\n",
    "            if i + 1 < len(sections):\n",
    "                title = sections[i+1].split('\\n')[0].strip()\n",
    "                current_file = f\"{title.lower().replace(' ', '-')}.md\"\n",
    "                if not current_file.endswith('.md'):\n",
    "                    current_file += '.md'\n",
    "        else:\n",
    "            current_content.append(f\"{'#' if i > 0 else ''}{section}\")\n",
    "\n",
    "    if current_content:\n",
    "        files.append((current_file, ''.join(current_content).strip()))\n",
    "\n",
    "    print(f\"Split into {len(files)} files.\")\n",
    "    return files\n",
    "\n",
    "def create_nav_structure(files):\n",
    "    \"\"\"\n",
    "    Create a navigation structure for mkdocs.yml based on the generated files.\n",
    "    \n",
    "    Args:\n",
    "    files (list): List of tuples containing (filename, content) for each section.\n",
    "    \n",
    "    Returns:\n",
    "    list: A nested list representing the nav structure.\n",
    "    \"\"\"\n",
    "    nav = []\n",
    "    for filename, _ in files:\n",
    "        if filename == 'index.md':\n",
    "            nav.append({\"Home\": \"index.md\"})\n",
    "        else:\n",
    "            title = ' '.join(word.capitalize() for word in filename[:-3].split('-'))\n",
    "            nav.append({title: filename})\n",
    "    return nav\n",
    "\n",
    "def create_mkdocs_config(site_name, site_description, nav):\n",
    "    \"\"\"\n",
    "    Create the MkDocs configuration dictionary.\n",
    "    \n",
    "    Args:\n",
    "    site_name (str): The name of the site.\n",
    "    site_description (str): A brief description of the site.\n",
    "    nav (list): The navigation structure for the site.\n",
    "    \n",
    "    Returns:\n",
    "    dict: MkDocs configuration dictionary.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        'site_name': site_name,\n",
    "        'site_url': 'https://www.example.com/',\n",
    "        'site_description': site_description,\n",
    "        'site_author': 'Ashvin',\n",
    "        'theme': {\n",
    "            'name': 'material',\n",
    "            'icon': {\n",
    "                'logo': 'material/view-grid-plus'\n",
    "            },\n",
    "            'favicon': 'assets/view-grid-plus-outline-dark.png',\n",
    "            'palette': [\n",
    "                {\n",
    "                    'scheme': 'default',\n",
    "                    'primary': 'teal',\n",
    "                    'accent': 'amber',\n",
    "                    'toggle': {\n",
    "                        'icon': 'material/lightbulb',\n",
    "                        'name': 'Switch to dark mode'\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    'scheme': 'slate',\n",
    "                    'primary': 'teal',\n",
    "                    'accent': 'amber',\n",
    "                    'toggle': {\n",
    "                        'icon': 'material/lightbulb-outline',\n",
    "                        'name': 'Switch to light mode'\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            'features': [\n",
    "                'content.code.copy',\n",
    "                'content.code.annotate'\n",
    "            ]\n",
    "        },\n",
    "        'markdown_extensions': [\n",
    "            'admonition',\n",
    "            'md_in_html',\n",
    "            'pymdownx.details',\n",
    "            {\n",
    "                'pymdownx.superfences': {\n",
    "                    'custom_fences': [\n",
    "                        {\n",
    "                            'name': 'mermaid',\n",
    "                            'class': 'mermaid',\n",
    "                            'format': '!!python/name:pymdownx.superfences.fence_code_format'\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            'attr_list'\n",
    "        ],\n",
    "        'copyright': 'Copyright © 2023-2024 Ashvin Parameswaran',\n",
    "        'extra': {\n",
    "            'social': [\n",
    "                {\n",
    "                    'icon': 'material/alpha-k-circle-outline',\n",
    "                    'link': 'https://ashvin.au'\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        'nav': nav\n",
    "    }\n",
    "    return config\n",
    "\n",
    "def generate_site(markdown_content, site_name, site_description):\n",
    "    \"\"\"\n",
    "    Generate the MkDocs site from the given markdown content.\n",
    "    \n",
    "    Args:\n",
    "    markdown_content (str): The full markdown content for the site.\n",
    "    site_name (str): The name of the site.\n",
    "    site_description (str): A brief description of the site.\n",
    "    \"\"\"\n",
    "    print(\"Starting site generation...\")\n",
    "    try:\n",
    "        # Create docs directory\n",
    "        docs_dir = Path('docs')\n",
    "        docs_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        files = split_markdown(markdown_content)\n",
    "        print(f\"Creating {len(files)} files...\")\n",
    "        for filename, content in files:\n",
    "            with open(docs_dir / filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "        \n",
    "        print(\"Creating mkdocs.yml...\")\n",
    "        nav = create_nav_structure(files)\n",
    "        config = create_mkdocs_config(site_name, site_description, nav)\n",
    "        with open('mkdocs.yml', 'w', encoding='utf-8') as f:\n",
    "            yaml.dump(config, f, allow_unicode=True)\n",
    "        print(\"Site generation complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during site generation: {e}\")\n",
    "        raise\n",
    "\n",
    "def launch_mkdocs():\n",
    "    \"\"\"\n",
    "    Launch the MkDocs server.\n",
    "    \"\"\"\n",
    "    print(\"Launching MkDocs server...\")\n",
    "    try:\n",
    "        process = subprocess.Popen(['mkdocs', 'serve'], \n",
    "                                   stdout=subprocess.PIPE, \n",
    "                                   stderr=subprocess.PIPE,\n",
    "                                   text=True)\n",
    "        \n",
    "        # Wait for a short time to see if the server starts successfully\n",
    "        try:\n",
    "            stdout, stderr = process.communicate(timeout=5)\n",
    "            print(\"MkDocs output:\")\n",
    "            print(stdout)\n",
    "            if stderr:\n",
    "                print(\"Errors:\")\n",
    "                print(stderr)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"MkDocs server is running. Access it at http://127.0.0.1:8000/\")\n",
    "            print(\"To stop the server, you'll need to interrupt the kernel.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: 'mkdocs' command not found. Make sure MkDocs is installed and in your PATH.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error launching MkDocs: {e}\")\n",
    "        print(\"You can try running 'mkdocs serve' in the terminal.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "markdown_content = final.response\n",
    "site_name = \"Applied LLMs\"\n",
    "site_description = \"Tactical, Operational and Strategic Tips\"\n",
    "\n",
    "\n",
    "try:\n",
    "    # Generate the site\n",
    "    generate_site(markdown_content, site_name, site_description)\n",
    "\n",
    "    # Launch MkDocs server\n",
    "    launch_mkdocs()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
