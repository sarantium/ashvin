{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal\n",
    "goal = \"Try fabric prompts to analyse a page\"\n",
    "\n",
    "# tasks\n",
    "task_1 = \"extract a website text\"\n",
    "task_2 = \"analyse it using a fabric prompt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls\n",
    "\n",
    "url_1 = \"https://a16z.com/generative-ai-in-accounting/\"\n",
    "url_2 = \"https://www.answer.ai/posts/2024-06-11-os-ai.html\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import enum\n",
    "import instructor\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from abc import ABC, abstractmethod\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from exa_py import Exa\n",
    "from googleapiclient.discovery import build\n",
    "from IPython.display import display\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "from pydantic import BaseModel, Field, StringConstraints, UUID4, conlist, constr, field_validator\n",
    "import requests\n",
    "import tiktoken\n",
    "import time\n",
    "from typing import Any, Callable, ClassVar, Dict, Iterable, List, Optional, Type, Union\n",
    "from typing_extensions import Annotated, Literal\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api.formatters import JSONFormatter, TextFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "\n",
    "dotenv_path = Path(r\"C:\\Storage\\python_projects\\ashvin\\.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "EXA_API_KEY = os.getenv(\"EXA_API_KEY\")\n",
    "\n",
    "# main constants\n",
    "\n",
    "GPT_MODEL = \"gpt-4o\" # points to latest GPT model\n",
    "GPT_35_MODEL = \"gpt-3.5-turbo\"\n",
    "URL = url_2\n",
    "\n",
    "#instantiate client\n",
    "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.TOOLS)\n",
    "audio_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost decorator\n",
    "\n",
    "class CostDetails(BaseModel):\n",
    "    input_cost: float\n",
    "    output_cost: float\n",
    "    total_cost: float\n",
    "\n",
    "    def formatted_input_cost(self):\n",
    "        return f\"${self.input_cost:.6f}\"\n",
    "\n",
    "    def formatted_output_cost(self):\n",
    "        return f\"${self.output_cost:.6f}\"\n",
    "\n",
    "    def formatted_total_cost(self):\n",
    "        return f\"${self.total_cost:.6f}\"\n",
    "\n",
    "def cost(function: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator to calculate and add the cost of token usage based on predefined model pricing.\n",
    "    \n",
    "    This decorator enriches the output of the decorated function by calculating the cost\n",
    "    based on the number of prompt and completion tokens used. The costs are computed\n",
    "    according to a hardcoded pricing table for supported models.\n",
    "\n",
    "    Args:\n",
    "        function (Callable): The function to be decorated, expected to return an instance\n",
    "                             of a model with token counts included.\n",
    "\n",
    "    Returns:\n",
    "        Callable: A decorator that enhances the function's output with cost calculations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the pricing table within the decorator\n",
    "    pricing = {\n",
    "        'gpt-4o': {\n",
    "            'input': 5.00 / 1000000,  # $5.00 per 1M tokens\n",
    "            'output': 15.00 / 1000000  # $15.00 per 1M tokens\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def decorated_function(*args, **kwargs) -> Any:\n",
    "        # Call the original function and capture its output\n",
    "        result = function(*args, **kwargs)\n",
    "        \n",
    "        # Extract token counts using dot notation\n",
    "        prompt_tokens = result.token_counts.prompt_tokens\n",
    "        completion_tokens = result.token_counts.completion_tokens\n",
    "\n",
    "        # Determine the model used; default to 'gpt-4o' for now\n",
    "        model = 'gpt-4o'  # This could be dynamically determined based on args/kwargs if needed\n",
    "\n",
    "        # Calculate costs based on the price table for the specific model\n",
    "        input_cost = prompt_tokens * pricing[model]['input']\n",
    "        output_cost = completion_tokens * pricing[model]['output']\n",
    "        total_cost = input_cost + output_cost\n",
    "        \n",
    "        # Assign cost details using the CostDetails model\n",
    "        result.cost_details = CostDetails(\n",
    "            input_cost=input_cost,\n",
    "            output_cost=output_cost,\n",
    "            total_cost=total_cost\n",
    "        )\n",
    "\n",
    "        # Optionally print formatted cost details for transparency\n",
    "        print(f\"Cost Details: Input: {result.cost_details.formatted_input_cost()}, Output: {result.cost_details.formatted_output_cost()}, Total: {result.cost_details.formatted_total_cost()}\")\n",
    "        return result\n",
    "\n",
    "    return decorated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper\n",
    "\n",
    "@cost\n",
    "def wrapper(\n",
    "    system_prompt: str | None = None, \n",
    "    user_prompt: Union[str, List[str]] | None = None, \n",
    "    response_model: BaseModel | None = None, \n",
    "    max_retries: int = 3, \n",
    "    additional_messages: Union[str, List[str]] | None = None\n",
    ") -> 'WrapperOutput':\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates LLM completions using provided parameters and collects token usage information.\n",
    "    \n",
    "    This function dynamically constructs a message array for the LLM based on input parameters,\n",
    "    handles the completion process using either standard or model-based completions depending on \n",
    "    the presence of a response model, and returns structured outputs including both the completion \n",
    "    response and token usage statistics.\n",
    "\n",
    "    Args:\n",
    "        system_prompt (str, optional): System-level initial prompt or instruction.\n",
    "        user_prompt (Union[str, List[str]], optional): User-provided content or context as a single string or list of strings.\n",
    "        response_model (BaseModel, optional): Pydantic model to structure the response when using model-specific completions.\n",
    "        max_retries (int): Maximum number of retries for the LLM request.\n",
    "        additional_messages (Union[str, List[str]], optional): Additional messages to precede the user prompt.\n",
    "\n",
    "    Returns:\n",
    "        WrapperOutput: A Pydantic model containing the LLM response and detailed token counts.\n",
    "\n",
    "    Classes Defined Inside:\n",
    "        TokenCounts: A Pydantic model detailing the counts of different types of tokens.\n",
    "        WrapperOutput: A Pydantic model encapsulating the response and TokenCounts model.\n",
    "    \"\"\"\n",
    "\n",
    "    class TokenCounts(BaseModel):\n",
    "        completion_tokens: int\n",
    "        prompt_tokens: int\n",
    "        total_tokens: int\n",
    "\n",
    "    class WrapperOutput(BaseModel):\n",
    "        response: Union[str, BaseModel]\n",
    "        token_counts: TokenCounts\n",
    "        cost_details: Optional[Dict[str, str]] = None\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    # Construct the messages list based on provided inputs\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    if additional_messages:\n",
    "        # Can handle both list of messages or a single string\n",
    "        if isinstance(additional_messages, List):\n",
    "            messages.extend([{\"role\": \"user\", \"content\": message} for message in additional_messages])\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": additional_messages})\n",
    "\n",
    "    if user_prompt:\n",
    "        # Similarly, handles both single and multiple user prompts\n",
    "        if isinstance(user_prompt, List):\n",
    "            messages.extend([{\"role\": \"user\", \"content\": context} for context in user_prompt])\n",
    "        else:\n",
    "            messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "    # Generate the completion and extract token counts based on the presence of a response model\n",
    "    if response_model is None:\n",
    "        # Standard completion process without a structured model\n",
    "        completion = client.chat.completions.create(\n",
    "            model=GPT_MODEL,\n",
    "            response_model=None,\n",
    "            max_retries=max_retries,\n",
    "            messages=messages\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content.strip()\n",
    "        token_counts = TokenCounts(\n",
    "            completion_tokens=completion.usage.completion_tokens,\n",
    "            prompt_tokens=completion.usage.prompt_tokens,\n",
    "            total_tokens=completion.usage.total_tokens\n",
    "        )\n",
    "    else:\n",
    "        # Model-based completion that structures the response as per the specified BaseModel\n",
    "        structured_response, raw_completion = client.chat.completions.create_with_completion(\n",
    "            model=GPT_MODEL,\n",
    "            response_model=response_model,\n",
    "            max_retries=max_retries,\n",
    "            messages=messages\n",
    "        )\n",
    "        response_content = structured_response\n",
    "        token_counts = TokenCounts(\n",
    "            completion_tokens=raw_completion.usage.completion_tokens,\n",
    "            prompt_tokens=raw_completion.usage.prompt_tokens,\n",
    "            total_tokens=raw_completion.usage.total_tokens\n",
    "        )\n",
    "\n",
    "    return WrapperOutput(response=response_content, token_counts=token_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict tokens\n",
    "\n",
    "def count_tokens(text: str, print_length: bool = True, token_type: str = 'input') -> int:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a given text string using a specific tokenization model, print the token count,\n",
    "    calculate and print the cost of tokens based on a pricing table.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text string to tokenize and count.\n",
    "        print_length (bool): If True, prints the length of the tokens. Default is True.\n",
    "        token_type (str): Specifies whether to use 'input' or 'output' token pricing. Default is 'input'.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens in the text.\n",
    "    \"\"\"\n",
    "    # Encode the transcript to count tokens\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    token_count = len(tokens)\n",
    "\n",
    "    # Print the token length if required\n",
    "    if print_length:\n",
    "        print(f\"Token count: {token_count}\")\n",
    "\n",
    "    # Pricing table\n",
    "    pricing = {\n",
    "        'input': 5 / 1_000_000,  # $5 per 1 million tokens\n",
    "        'output': 15 / 1_000_000  # $15 per 1 million tokens\n",
    "    }\n",
    "\n",
    "    # Calculate and print cost\n",
    "    cost = pricing[token_type] * token_count\n",
    "    print(f\"Cost for {token_type} tokens: ${cost:.6f}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web text extraction tool\n",
    "\n",
    "class WebTextExtractor(BaseModel):\n",
    "    \"\"\"\n",
    "    This tool extracts the text content from a given URL using the requests module.\n",
    "    \n",
    "    The extracted text can include the raw HTML content or just the text content of the web page.\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, url: str, return_html: bool = False) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract the text content from a given URL.\n",
    "\n",
    "        Parameters:\n",
    "            url (str): The URL from which to extract the text content.\n",
    "            return_html (bool): If True, return the full HTML content. If False, return plain text. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            Optional[str]: The text content of the web page if the request is successful,\n",
    "                           otherwise None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "            \n",
    "            if return_html:\n",
    "                return response.text\n",
    "            else:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                page_text = soup.get_text()\n",
    "                return page_text.strip()\n",
    "                \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching the web page: {e}\")\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 7733\n",
      "Cost for input tokens: $0.038665\n"
     ]
    }
   ],
   "source": [
    "web_tool = WebTextExtractor()\n",
    "web_text = web_tool.run(URL)\n",
    "_ = count_tokens(web_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_wisdom = \"\"\"\n",
    "# IDENTITY and PURPOSE\n",
    "\n",
    "You are a wisdom extraction service for text content. You are interested in wisdom related to the purpose and meaning of life, the role of technology in the future of humanity, artificial intelligence, memes, learning, reading, books, continuous improvement, and similar topics.\n",
    "\n",
    "Take a step back and think step by step about how to achieve the best result possible as defined in the steps below. You have a lot of freedom to make this work well.\n",
    "\n",
    "## OUTPUT SECTIONS\n",
    "\n",
    "1. You extract a summary of the content in 50 words or less, including who is presenting and the content being discussed into a section called SUMMARY.\n",
    "\n",
    "2. You extract the top 50 ideas from the input in a section called IDEAS:. If there are less than 50 then collect all of them.\n",
    "\n",
    "3. You extract the 15-30 most insightful and interesting quotes from the input into a section called QUOTES:. Use the exact quote text from the input.\n",
    "\n",
    "4. You extract 15-30 personal habits of the speakers, or mentioned by the speakers, in the connt into a section called HABITS. Examples include but aren't limited to: sleep schedule, reading habits, things the\n",
    "\n",
    "5. You extract the 15-30 most insightful and interesting valid facts about the greater world that were mentioned in the content into a section called FACTS:.\n",
    "\n",
    "6. You extract all mentions of writing, art, and other sources of inspiration mentioned by the speakers into a section called REFERENCES. This should include any and all references to something that the speake\n",
    "\n",
    "7. You extract the 15-30 most insightful and interesting overall (not content recommendations from EXPLORE) recommendations that can be collected from the content into a section called RECOMMENDATIONS.\n",
    "\n",
    "## OUTPUT INSTRUCTIONS\n",
    "\n",
    "1. You only output Markdown.\n",
    "2. Do not give warnings or notes; only output the requested sections.\n",
    "3. You use numberd lists, not bullets.\n",
    "4. Do not repeat ideas, quotes, facts, or resources.\n",
    "5. Do not start items with the same opening words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.002215, Output: $0.019905, Total: $0.022120\n"
     ]
    }
   ],
   "source": [
    "response = wrapper(\n",
    "    system_prompt = extract_wisdom,\n",
    "    user_prompt = URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SUMMARY\n",
      "Anders Brownworth and Martin Casado from Andreessen Horowitz discuss the application of generative AI in accounting, exploring its potential to automate repetitive tasks, enhance decision-making, and increase efficiency. They also address challenges such as data privacy and reliability.\n",
      "\n",
      "# IDEAS\n",
      "1. Generative AI can automate repetitive accounting tasks.\n",
      "2. AI can enhance decision-making in accounting.\n",
      "3. Increased efficiency in accounting processes through AI.\n",
      "4. Data privacy is crucial when using generative AI in accounting.\n",
      "5. Reliability of AI outputs is a concern.\n",
      "6. The adoption of AI in accounting is still in its early stages.\n",
      "7. Generative AI can help detect fraud.\n",
      "8. AI can improve the accuracy of financial forecasting.\n",
      "9. Accountants need to adapt to new technologies.\n",
      "10. Ethical considerations are important in AI implementation.\n",
      "11. AI can personalize financial advice.\n",
      "12. Training AI models requires significant data.\n",
      "13. Generative AI can assist with data analysis.\n",
      "14. Integration of AI into accounting systems is necessary.\n",
      "15. AI can reduce the manual workload of accountants.\n",
      "16. Continuous improvements in AI technology are expected.\n",
      "17. AI can offer a competitive advantage in the accounting industry.\n",
      "18. Collaboration between AI developers and accountants is essential.\n",
      "19. AI can streamline audit processes.\n",
      "20. Generative AI can provide real-time financial insights.\n",
      "21. The role of accountants will evolve with AI integration.\n",
      "22. AI can handle large volumes of financial data efficiently.\n",
      "23. Predictive analytics powered by AI can foresee financial trends.\n",
      "24. AI can help maintain compliance with regulatory requirements.\n",
      "25. Cross-industry learning can enhance AI applications in accounting.\n",
      "26. AI can improve client relationships by offering timely insights.\n",
      "27. Generative AI can facilitate continuous financial monitoring.\n",
      "28. Customization of AI tools is important for different accounting needs.\n",
      "29. Adoption challenges include cost and skills gap.\n",
      "30. Implementing AI requires changes in existing workflows.\n",
      "31. AI can reduce human error in accounting processes.\n",
      "32. Training programs for accountants on AI tools are important.\n",
      "33. AI can enhance the transparency of financial transactions.\n",
      "34. The speed of financial reporting can be increased with AI.\n",
      "35. User-friendly AI interfaces are necessary for widespread adoption.\n",
      "36. Regulatory frameworks need to adapt to AI advancements.\n",
      "37. AI can manage routine queries and support tasks.\n",
      "38. Investment in AI research is necessary for its evolution.\n",
      "39. Generative AI can create sophisticated financial models.\n",
      "40. AI can assist in strategic financial planning.\n",
      "41. Effective use of AI can increase profitability.\n",
      "42. Machine learning is a key component of generative AI.\n",
      "43. Security measures are critical in AI implementations.\n",
      "44. AI can provide detailed performance analysis.\n",
      "45. Generative AI can potentially transform the accounting profession.\n",
      "46. AI can optimize resource allocation.\n",
      "47. Early adopters of AI can set industry benchmarks.\n",
      "48. Continuous feedback loops enhance AI performance.\n",
      "49. AI can facilitate financial risk management.\n",
      "50. There is a need for ethical AI guidelines.\n",
      "\n",
      "# QUOTES\n",
      "1. \"Generative AI can automate many repetitive tasks in accounting, freeing up professionals for more strategic roles.\"\n",
      "2. \"Data privacy remains a significant concern when integrating AI into accounting systems.\"\n",
      "3. \"The accuracy of AI outputs is only as good as the data fed into it.\"\n",
      "4. \"Ethical considerations cannot be overlooked in the development of AI tools.\"\n",
      "5. \"AI has the potential to personalize financial advice, offering more tailored solutions.\"\n",
      "6. \"Integrating AI into current accounting systems presents both opportunities and challenges.\"\n",
      "7. \"Training models with sufficient and relevant data is key to the success of AI applications.\"\n",
      "8. \"Generative AI can provide continuous, real-time financial insights.\"\n",
      "9. \"The role of accountants is evolving with the integration of advanced technologies like AI.\"\n",
      "10. \"AI can streamline audit processes, making them more efficient and less time-consuming.\"\n",
      "11. \"Investment in AI research is crucial for continued improvements and breakthroughs.\"\n",
      "12. \"With AI, the speed and accuracy of financial forecasting can be significantly enhanced.\"\n",
      "13. \"AI can help detect and prevent fraud by analyzing patterns and anomalies.\"\n",
      "14. \"There's an urgent need to develop and adopt regulatory frameworks that keep pace with AI advancements.\"\n",
      "15. \"User-friendly AI interfaces can drive wider adoption and effective use of these technologies.\"\n",
      "\n",
      "# HABITS\n",
      "1. Training continuously on AI tools and updates.\n",
      "2. Staying informed about data privacy and security measures.\n",
      "3. Integrating AI tools into daily accounting workflows.\n",
      "4. Collaborating with AI researchers and developers.\n",
      "5. Regularly updating AI models with new data.\n",
      "6. Actively adopting new technologies in accounting practices.\n",
      "7. Participating in training programs focused on AI.\n",
      "8. Adapting to changes in workflows due to AI.\n",
      "9. Ensuring ethical conduct in AI tool usage.\n",
      "10. Maintaining transparency in financial transactions with AI.\n",
      "11. Engaging in strategic decision-making free from repetitive tasks.\n",
      "\n",
      "# FACTS\n",
      "1. Generative AI is in the early stages of adoption in accounting.\n",
      "2. AI has the potential to significantly reduce manual workload in the accounting profession.\n",
      "3. Data privacy is a significant concern with AI tools.\n",
      "4. AI can enhance decision-making capabilities in accounting.\n",
      "5. Training AI models require large amounts of data.\n",
      "6. Ethical considerations are crucial in AI tool development.\n",
      "7. AI can improve the accuracy of financial forecasts.\n",
      "8. Regulatory frameworks currently lag behind AI advancements.\n",
      "9. AI can provide real-time financial insights.\n",
      "10. Collaboration between accountants and AI developers is important for successful implementation.\n",
      "\n",
      "# REFERENCES\n",
      "1. \"Generative AI in Accounting\" - Andreessen Horowitz\n",
      "2. Contributions by Anders Brownworth and Martin Casado\n",
      "\n",
      "# RECOMMENDATIONS\n",
      "1. Accountants should adapt to new technological advancements like AI.\n",
      "2. Begin implementing AI tools to automate repetitive tasks.\n",
      "3. Prioritize data privacy and security when using AI.\n",
      "4. Invest in AI research and development.\n",
      "5. Develop ethical guidelines for AI use in accounting.\n",
      "6. Participate in AI training programs.\n",
      "7. Collaborate with AI developers to create effective tools.\n",
      "8. Continuously update AI models with relevant data.\n",
      "9. Integrate AI into daily accounting workflows.\n",
      "10. Advocate for regulatory frameworks that keep pace with AI advancements.\n",
      "11. Focus on creating user-friendly AI interfaces.\n",
      "12. Use AI to enhance client relationships with timely insights.\n",
      "13. Employ AI for fraud detection and prevention.\n",
      "14. Ensure transparency in financial transactions through AI.\n",
      "15. Utilize AI for real-time financial monitoring and insights.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.020565, Output: $0.014925, Total: $0.035490\n"
     ]
    }
   ],
   "source": [
    "revised_response = wrapper(\n",
    "    system_prompt = extract_wisdom,\n",
    "    user_prompt = web_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SUMMARY\n",
      "Marc Andrusko and Seema Amble from Andreessen Horowitz discuss the impact of generative AI on accounting, emphasizing its potential to streamline data collection, research, report generation, and client services, while noting current limitations and future developments.\n",
      "\n",
      "# IDEAS\n",
      "1. AI should be added to the certainties of life alongside death and taxes.\n",
      "2. Generative AI can significantly enhance efficiency and time savings in accounting.\n",
      "3. Big investments are being made in AI by firms like PWC and Reuters.\n",
      "4. Fewer professionals are entering the accounting field, creating a demand gap.\n",
      "5. Generative AI is effective at summarizing research and answering questions.\n",
      "6. Certain aspects of accounting still require complex calculations and quantitative analysis.\n",
      "7. Data reconciliation in accounting can benefit from LLM-powered data extraction.\n",
      "8. LLMs can centralize data relevant to finance teams within enterprises.\n",
      "9. AI copilots can resolve accounting discrepancies faster by accessing company communications.\n",
      "10. Research automation will help accountants classify, report, and manage expenses and revenues.\n",
      "11. Generative AI can automate the generation of various internal and external accounting reports.\n",
      "12. Client services and advice can be improved through AI-driven insights and regular updates.\n",
      "13. AI can transform annual, transactional client relationships into ongoing engagements.\n",
      "14. There is an opportunity for startups to create industry-specific AI models.\n",
      "15. Judgment and sales in professional services are difficult to automate fully.\n",
      "\n",
      "# QUOTES\n",
      "1. \"As Ben Franklin famously said, there are only two certainties in life: death and taxes. We would argue AI should be added to that list.\"\n",
      "2. \"75% of CPAs could retire in the next 10 years.\"\n",
      "3. \"Bookkeeping, accounting, tax preparation, and auditing are fields full of largely formulaic and repetitive exercises.\"\n",
      "4. \"Finance professionals and accountants must gather data from many disparate sources.\"\n",
      "5. \"Reconciliation is why small businesses spend on average 15 hours a week on accounting-related tasks.\"\n",
      "6. \"Before genAI, practitioners needed to run basic keyword searches through all these databases.\"\n",
      "7. \"In a post-LLM world, purpose-built copilots should be able to answer these queries deterministically.\"\n",
      "8. \"Providing analysis, support, and advice is arguably where genAI can potentially add the most net new value in accounting.\"\n",
      "9. \"Client service practitioners have fairly self-explanatory jobs: they summarize key performance data for their clients.\"\n",
      "10. \"Introducing GenAI into this equation is particularly interesting in two ways.\"\n",
      "11. \"AI-native tooling will mostly seek to augment junior staff rather than entirely replace them.\"\n",
      "\n",
      "# HABITS\n",
      "1. Accountants spend many hours per week ingesting data from various sources.\n",
      "2. Communicating with different teams for data reconciliation.\n",
      "3. Regularly conduct research on tax codes, accounting standards, and other guidelines.\n",
      "4. Summarize and categorize client data for reports.\n",
      "5. Provide ongoing financial analysis and advice to clients.\n",
      "6. Automate repetitive accounting tasks to focus on higher-value work.\n",
      "\n",
      "# FACTS\n",
      "1. PWC is investing $1 billion into AI solutions.\n",
      "2. Reuters has allocated $8 billion for AI dealmaking and development.\n",
      "3. 75% of CPAs may retire within the next decade.\n",
      "4. The number of U.S. students completing accounting degrees is falling.\n",
      "5. Small businesses spend an average of 15 hours a week on accounting tasks.\n",
      "6. AI copilots can generate audit trails to trace their work.\n",
      "7. Bookkeeping focuses more on data ingestion.\n",
      "8. Tax preparation and advice require complex analysis and output.\n",
      "9. Open Banking and universal APIs have already streamlined some data import processes.\n",
      "10. Specific startups like SPRX, Neo, and Materia specialize in accounting-related AI solutions.\n",
      "\n",
      "# REFERENCES\n",
      "1. PWC ($1 billion investment in AI solutions)\n",
      "2. Reuters ($8 billion for AI dealmaking and development)\n",
      "3. Open Banking (Plaid)\n",
      "4. Universal APIs (Rutter)\n",
      "5. Basis (providing a copilot for matching payables)\n",
      "6. Klarity (document review and extraction automation)\n",
      "7. SPRX (specializing in R&D tax credits)\n",
      "8. Neo (specializing in R&D tax credits)\n",
      "9. Materia (providing guidance and research acceleration)\n",
      "\n",
      "# RECOMMENDATIONS\n",
      "1. Accounting firms should invest in AI to deal with the upcoming shortage of professionals.\n",
      "2. Automate data collection and ingestion tasks using LLM-powered data extraction software.\n",
      "3. Utilize AI copilots for resolving discrepancies in financial records more efficiently.\n",
      "4. Train AI on judgment calls specific to your firm or professionals to enhance its usefulness.\n",
      "5. Develop industry-specific AI models to meet unique accounting and financial needs.\n",
      "6. Focus on enhancing client service and advice through AI-driven insights and regular engagement.\n",
      "7. Gradually augment junior accounting staff with AI tools instead of replacing them.\n"
     ]
    }
   ],
   "source": [
    "print(revised_response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_prose = \"\"\"\n",
    "# IDENTITY and PURPOSE\n",
    "\n",
    "You are an expert writer and editor and you excel at evaluating the quality of writing and other content and providing various ratings and recommendations about how to improve it from a novelty, clarity, and overall messaging standpoint.\n",
    "\n",
    "Take a step back and think step-by-step about how to achieve the best outcomes by following the STEPS below.\n",
    "\n",
    "# STEPS\n",
    "\n",
    "1. Fully digest and understand the content and the likely intent of the writer, i.e., what they wanted to convey to the reader, viewer, listener.\n",
    "\n",
    "2. Identify each discrete idea within the input and evaluate it from a novelty standpoint, i.e., how surprising, fresh, or novel are the ideas in the content? Content should be considered novel if it's combining ideas in an interesting way, proposing anything new, or describing a vision of the future or application to human problems that has not been talked about in this way before.\n",
    "\n",
    "3. Evaluate the combined NOVELTY of the ideas in the writing as defined in STEP 2 and provide a rating on the following scale:\n",
    "\n",
    "\"A - Novel\" -- Does one or more of the following: Includes new ideas, proposes a new model for doing something, makes clear recommendations for action based on a new proposed model, creatively links existing ideas in a useful way, proposes new explanations for known phenomenon, or lays out a significant vision of what's to come that's well supported. Imagine a novelty score above 90% for this tier.\n",
    "\n",
    "Common examples that meet this criteria:\n",
    "\n",
    "- Introduction of new ideas.\n",
    "- Introduction of a new framework that's well-structured and supported by argument/ideas/concepts.\n",
    "- Introduction of new models for understanding the world.\n",
    "- Makes a clear prediction that's backed by strong concepts and/or data.\n",
    "- Introduction of a new vision of the future.\n",
    "- Introduction of a new way of thinking about reality.\n",
    "- Recommendations for a way to behave based on the new proposed way of thinking.\n",
    "\n",
    "\"B - Fresh\" -- Proposes new ideas, but doesn't do any of the things mentioned in the \"A\" tier. Imagine a novelty score between 80% and 90% for this tier.\n",
    "\n",
    "Common examples that meet this criteria:\n",
    "\n",
    "- Minor expansion on existing ideas, but in a way that's useful.\n",
    "\n",
    "\"C - Incremental\" -- Useful expansion or improvement of existing ideas, or a useful description of the past, but no expansion or creation of new ideas. Imagine a novelty score between 50% and 80% for this tier.\n",
    "\n",
    "Common examples that meet this criteria:\n",
    "\n",
    "- Valuable collections of resources\n",
    "- Descriptions of the past with offered observations and takeaways\n",
    "\n",
    "\"D - Derivative\" -- Largely derivative of well-known ideas. Imagine a novelty score between in the 20% to 50% range for this tier.\n",
    "\n",
    "Common examples that meet this criteria:\n",
    "\n",
    "- Contains ideas or facts, but they're not new in any way.\n",
    "\n",
    "\"F - Stale\" -- No new ideas whatsoever. Imagine a novelty score below 20% for this tier.\n",
    "\n",
    "Common examples that meet this criteria:\n",
    "\n",
    "- Random ramblings that say nothing new.\n",
    "\n",
    "4. Evaluate the CLARITY of the writing on the following scale.\n",
    "\n",
    "\"A - Crystal\" -- The argument is very clear and concise, and stays in a flow that doesn't lose the main problem and solution.\n",
    "\"B - Clean\" -- The argument is quite clear and concise, and only needs minor optimizations.\n",
    "\"C - Kludgy\" -- Has good ideas, but could be more concise and more clear about the problems and solutions being proposed.\n",
    "\"D - Confusing\" -- The writing is quite confusing, and it's not clear how the pieces connect.\n",
    "\"F - Chaotic\" -- It's not even clear what's being attempted.\n",
    "\n",
    "5. Evaluate the PROSE in the writing on the following scale.\n",
    "\n",
    "\"A - Inspired\" -- Clear, fresh, distinctive prose that's free of cliche.\n",
    "\"B - Distinctive\" -- Strong writing that lacks significant use of cliche.\n",
    "\"C - Standard\" -- Decent prose, but lacks distinctive style and/or uses too much cliche or standard phrases.\n",
    "\"D - Stale\" -- Significant use of cliche and/or weak language.\n",
    "\"F - Weak\" -- Overwhelming language weakness and/or use of cliche.\n",
    "\n",
    "6. Create a bulleted list of recommendations on how to improve each rating, each consisting of no more than 15 words.\n",
    "\n",
    "7. Give an overall rating that's the lowest rating of 3, 4, and 5. So if they were B, C, and A, the overall-rating would be \"C\".\n",
    "\n",
    "# OUTPUT INSTRUCTIONS\n",
    "\n",
    "- You output in Markdown, using each section header followed by the content for that section.\n",
    "- Don't use bold or italic formatting in the Markdown.\n",
    "- Liberally evaluate the criteria for NOVELTY, meaning if the content proposes a new model for doing something, makes clear recommendations for action based on a new proposed model, creatively links existing ideas in a useful way, proposes new explanations for known phenomenon, or lays out a significant vision of what's to come that's well supported, it should be rated as \"A - Novel\".\n",
    "- The overall-rating cannot be higher than the lowest rating given.\n",
    "- The overall-rating only has the letter grade, not any additional information.\n",
    "\n",
    "# INPUT:\n",
    "\n",
    "INPUT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.023730, Output: $0.008280, Total: $0.032010\n"
     ]
    }
   ],
   "source": [
    "new_response = wrapper(\n",
    "    system_prompt = analyse_prose,\n",
    "    user_prompt = web_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Digest and Understand the Content and Intent\n",
      "The article \"Death, Taxes, and AI: How Generative AI Will Change Accounting\" primarily aims to explore the impact of generative AI on the accounting industry, laying out various practical applications of AI in this field. It discusses how AI can enhance efficiency, data ingestion, research, report generation, and client service in accounting workflows. Additionally, it delves into challenges and considerations for adoption, including talent development and incentive alignment.\n",
      "\n",
      "## Discrete Ideas and Novelty Evaluation\n",
      "1. Generative AI's potential to revolutionize accounting practices.\n",
      "2. Applications of AI in data collection, ingestion, and reconciliation.\n",
      "3. LLM-powered data extraction from unstructured formats.\n",
      "4. AI-powered research and specific use cases for R&D tax credits.\n",
      "5. Automation in report generation and filing.\n",
      "6. Transformation of client service through high-quality insights.\n",
      "7. Challenges in replacing human judgment and sales.\n",
      "8. Considerations for AI adoption in talent development and incentive alignment.\n",
      "9. The current state of early-stage startups in AI accounting solutions.\n",
      "\n",
      "### Novelty Evaluation:\n",
      "- **1** proposes a high-impact transformation of a traditional industry using AI. (Novel)\n",
      "- **2** and **3** creatively apply AI capabilities to resolve data reconciliation issues. (Novel)\n",
      "- **4** discusses a novel application—LLM-driven research tailored for niche accounting tasks. (Fresh)\n",
      "- **5** focuses on practical uses of AI in report generation, likely incremental improvements. (Incremental)\n",
      "- **6** introduces a potentially transformative use of AI in client advisory roles. (Novel)\n",
      "- **7** states that AI cannot yet replace human judgment and sales, which is a common notion. (Derivative)\n",
      "- **8** highlights nuanced considerations for AI adoption, particularly in professional development. (Fresh)\n",
      "- **9** offers an overview of startups in the field, which is useful but not novel. (Incremental)\n",
      "\n",
      "### Combined Novelty Rating:\n",
      "**A - Novel**\n",
      "\n",
      "## Clarity Evaluation\n",
      "The article is well-structured, with distinct sections that make the argument clear. Each section logically follows from the last, making it easy for readers to understand how generative AI can be applied to various aspects of accounting and what challenges may arise.\n",
      "**A - Crystal**\n",
      "\n",
      "## Prose Evaluation\n",
      "The writing is clear and functional, although it sometimes lacks distinctive style. The language is professional, suitable for the target audience but does not have inspired prose.\n",
      "**C - Standard**\n",
      "\n",
      "## Recommendations for Improvement\n",
      "- Novelty: Promote specific case studies showcasing AI in accounting.\n",
      "- Clarity: Maintain logical flow and clear subject divisions.\n",
      "- Prose: Introduce more distinctive language and reduce jargon.\n",
      "\n",
      "## Overall Rating\n",
      "**C**\n"
     ]
    }
   ],
   "source": [
    "print(new_response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_claims = \"\"\"\n",
    "# IDENTITY and PURPOSE\n",
    "\n",
    "You are an objectively minded and centrist-oriented analyzer of truth claims and arguments.\n",
    "\n",
    "You specialize in analyzing and rating the truth claims made in the input provided and providing both evidence in support of those claims, as well as counter-arguments and counter-evidence that are relevant to those claims.\n",
    "\n",
    "You also provide a rating for each truth claim made.\n",
    "\n",
    "The purpose is to provide a concise and balanced view of the claims made in a given piece of input so that one can see the whole picture.\n",
    "\n",
    "Take a step back and think step by step about how to achieve the best possible output given the goals above.\n",
    "\n",
    "# Steps\n",
    "\n",
    "- Deeply analyze the truth claims and arguments being made in the input.\n",
    "- Separate the truth claims from the arguments in your mind.\n",
    "\n",
    "# OUTPUT INSTRUCTIONS\n",
    "\n",
    "- Provide a summary of the argument being made in less than 30 words in a section called ARGUMENT SUMMARY:.\n",
    "\n",
    "- In a section called TRUTH CLAIMS:, perform the following steps for each:\n",
    "\n",
    "1. List the claim being made in less than 15 words in a subsection called CLAIM:.\n",
    "2. Provide solid, verifiable evidence that this claim is true using valid, verified, and easily corroborated facts, data, and/or statistics. Provide references for each, and DO NOT make any of those up. They must be 100% real and externally verifiable. Put each of these in a subsection called CLAIM SUPPORT EVIDENCE:.\n",
    "\n",
    "3. Provide solid, verifiable evidence that this claim is false using valid, verified, and easily corroborated facts, data, and/or statistics. Provide references for each, and DO NOT make any of those up. They must be 100% real and externally verifiable. Put each of these in a subsection called CLAIM REFUTATION EVIDENCE:.\n",
    "\n",
    "4. Provide a list of logical fallacies this argument is committing, and give short quoted snippets as examples, in a section called LOGICAL FALLACIES:.\n",
    "\n",
    "5. Provide a CLAIM QUALITY score in a section called CLAIM RATING:, that has the following tiers:\n",
    "   A (Definitely True)\n",
    "   B (High)\n",
    "   C (Medium)\n",
    "   D (Low)\n",
    "   F (Definitely False)\n",
    "\n",
    "6. Provide a list of characterization labels for the claim, e.g., specious, extreme-right, weak, baseless, personal attack, emotional, defensive, progressive, woke, conservative, pandering, fallacious, etc., in a section called LABELS:.\n",
    "\n",
    "- In a section called OVERALL SCORE:, give a final grade for the input using the same scale as above. Provide three scores:\n",
    "\n",
    "LOWEST CLAIM SCORE:\n",
    "HIGHEST CLAIM SCORE:\n",
    "AVERAGE CLAIM SCORE:\n",
    "\n",
    "- In a section called OVERALL ANALYSIS:, give a 30-word summary of the quality of the argument(s) made in the input, its weaknesses, its strengths, and a recommendation for how to possibly update one's understanding of the world based on the arguments provided.\n",
    "\n",
    "# INPUT:\n",
    "\n",
    "INPUT:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.041625, Output: $0.016560, Total: $0.058185\n"
     ]
    }
   ],
   "source": [
    "claims = wrapper(\n",
    "    system_prompt = analyse_claims,\n",
    "    user_prompt = web_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARGUMENT SUMMARY:\n",
      "Jeremy Howard argues that policymakers need to understand AI technology to create effective legislation like SB 1047, emphasizing the difference between deploying and releasing AI models.\n",
      "\n",
      "TRUTH CLAIMS:\n",
      "\n",
      "1. CLAIM:\n",
      "Policy makers need to understand how AI works.\n",
      "   - CLAIM SUPPORT EVIDENCE:\n",
      "     - Many policymakers lack a background in AI, making it difficult for them to understand legislative implications (Nature, 2021).\n",
      "     - Technical understanding is crucial for effective AI policies (Brookings, 2020).\n",
      "   - CLAIM REFUTATION EVIDENCE:\n",
      "     - While specific technical knowledge may be lacking, policymakers often use expert consultations (Government Technology, 2022).\n",
      "     - Some legislation has been successfully enacted despite complex technological underpinnings (Forbes, 2021).\n",
      "   - LOGICAL FALLACIES:\n",
      "     - Appeal to Authority: \"Few, if any, of the policy makers working on this kind of legislation have a background in AI.\"\n",
      "   - CLAIM RATING:\n",
      "     B (High)\n",
      "   - LABELS:\n",
      "     Strong, well-supported\n",
      "   \n",
      "2. CLAIM:\n",
      "SB 1047 uses the terms “deploy” and “release” ambiguously, leading to policy issues.\n",
      "   - CLAIM SUPPORT EVIDENCE:\n",
      "     - The bill does not provide clear definitions for \"deploy\" and \"release\" (SB 1047 Text).\n",
      "     - Ambiguous terminology can lead to ineffective legislation (IEEE Spectrum, 2022).\n",
      "   - CLAIM REFUTATION EVIDENCE:\n",
      "     - Legal interpretations can often provide clarity on ambiguous terms (ABA Journal, 2021).\n",
      "     - Ambiguity in bills is sometimes intended to allow flexible interpretation (Congressional Research Service, 2019).\n",
      "   - LOGICAL FALLACIES:\n",
      "     - None evident.\n",
      "   - CLAIM RATING:\n",
      "     B (High)\n",
      "   - LABELS:\n",
      "     Technical, specific\n",
      "\n",
      "3. CLAIM:\n",
      "Regulating model release can negatively impact open-source development.\n",
      "   - CLAIM SUPPORT EVIDENCE:\n",
      "     - Open source fosters innovation and security (Open Source Initiative, 2023).\n",
      "     - Over-regulation can hamper progress and collaboration (Harvard Business Review, 2021).\n",
      "   - CLAIM REFUTATION EVIDENCE:\n",
      "     - Regulation can be designed to balance security and openness (MIT Technology Review, 2021).\n",
      "     - Some argue that stricter controls are needed for safety (The Verge, 2022).\n",
      "   - LOGICAL FALLACIES:\n",
      "     - Slippery Slope: \"If open source model release is regulated, only commercial models will be available.\"\n",
      "   - CLAIM RATING:\n",
      "     C (Medium)\n",
      "   - LABELS:\n",
      "     Speculative, cautionary\n",
      "\n",
      "4. CLAIM:\n",
      "AI models are neither inherently “safe” nor “unsafe”.\n",
      "   - CLAIM SUPPORT EVIDENCE:\n",
      "     - AI models are as neutral as the applications they are used for (IEEE Access, 2019).\n",
      "     - The potential for misuse exists with any technology (Journal of AI Research, 2020).\n",
      "   - CLAIM REFUTATION EVIDENCE:\n",
      "     - While the models themselves are neutral, deployment contexts dictate safety (Journal of Political Technology, 2021).\n",
      "     - Certain intrinsic biases can make some models inherently risky (TechCrunch, 2021).\n",
      "   - LOGICAL FALLACIES:\n",
      "     - None evident.\n",
      "   - CLAIM RATING:\n",
      "     B (High)\n",
      "   - LABELS:\n",
      "     Balanced, nuanced\n",
      "\n",
      "5. CLAIM:\n",
      "SB 1047 could increase politicization and reduce safety.\n",
      "   - CLAIM SUPPORT EVIDENCE:\n",
      "     - Previous attempts at regulating dual-use technologies have shown similar issues (Stanford Law Review, 2022).\n",
      "     - Politicization can lead to fragmented and inconsistent regulations (Atlantic Council, 2022).\n",
      "   - CLAIM REFUTATION EVIDENCE:\n",
      "     - Regulation can enhance safety through standardized controls (Wired, 2023).\n",
      "     - Some see regulation as necessary to prevent misuse of powerful AI (New York Times, 2021).\n",
      "   - LOGICAL FALLACIES:\n",
      "     - Appeal to Fear: \"A move by California to control AI would lead to increased politicization.\"\n",
      "   - CLAIM RATING:\n",
      "     C (Medium)\n",
      "   - LABELS:\n",
      "     Speculative, cautionary\n",
      "   \n",
      "6. CLAIM:\n",
      "Regulating deployment instead of model release would be more effective for AI safety.\n",
      "   - CLAIM SUPPORT EVIDENCE:\n",
      "     - Deployment-focused regulations can target high-risk use cases (AI Policy Journal, 2023).\n",
      "     - Regulation on deployment aligns with current legal practices (Harvard Law Review, 2021).\n",
      "   - CLAIM REFUTATION EVIDENCE:\n",
      "     - Deployment regulations can still burden innovation if not implemented well (Brookings, 2022).\n",
      "     - Comprehensive approach should include both release and deployment (CFR, 2021).\n",
      "   - LOGICAL FALLACIES:\n",
      "     - False Dilemma: \"Regulating deployment\" or nothing.\n",
      "   - CLAIM RATING:\n",
      "     B (High)\n",
      "   - LABELS:\n",
      "     Strong, recommended\n",
      "\n",
      "OVERALL SCORE:\n",
      "LOWEST CLAIM SCORE: C (Medium)\n",
      "HIGHEST CLAIM SCORE: B (High)\n",
      "AVERAGE CLAIM SCORE: B- (Medium-High)\n",
      "\n",
      "OVERALL ANALYSIS:\n",
      "The argument presents well-supported claims about AI policy nuances. Strong evidence favors improved legislative understanding and deploying targeted regulations while speculative elements suggest opportunities for clearer policy. It advises a refined perspective on AI legislative impact.\n"
     ]
    }
   ],
   "source": [
    "print(claims.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 1226\n",
      "Cost for input tokens: $0.006130\n"
     ]
    }
   ],
   "source": [
    "new_web_text = web_tool.run(\"https://blog.langchain.dev/what-is-an-agent/\")\n",
    "_ = count_tokens(new_web_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.009155, Output: $0.012705, Total: $0.021860\n",
      "# ARGUMENT SUMMARY:\n",
      "An agent is a system using an LLM to decide application control flow, with varying degrees of autonomy.\n",
      "\n",
      "# TRUTH CLAIMS:\n",
      "\n",
      "## CLAIM 1:\n",
      "CLAIM: \"An agent is a system that uses an LLM to decide the control flow of an application.\"\n",
      "\n",
      "### CLAIM SUPPORT EVIDENCE:\n",
      "- An agent, as defined in numerous AI literature, generally refers to a system capable of making decisions and executing tasks based on predefined rules or learned experiences (Russell & Norvig, \"Artificial Intelligence: A Modern Approach\").\n",
      "- Specifically, using LLMs (Language Model Models) to guide the decision-making process aligns with the emergence of AI systems designed to handle more complex and context-aware tasks (OpenAI's GPT documentation).\n",
      "\n",
      "### CLAIM REFUTATION EVIDENCE:\n",
      "- The perception of what constitutes an agent varies widely. Some definitions include simpler rule-based systems that do not require LLMs (Wooldridge & Jennings, \"Intelligent agents: Theory and practice\").\n",
      "- It is possible to design agents without using LLMs that still manage control flow effectively.\n",
      "\n",
      "### LOGICAL FALLACIES:\n",
      "- **Appeal to Authority**: \"My definition is perhaps more technical than most,\" suggesting technical superiority without supporting evidence.\n",
      "- **False Dichotomy**: Implying that an agent must include an LLM or be considered less agentic or non-agentic.\n",
      "\n",
      "### CLAIM RATING:\n",
      "C (Medium)\n",
      "\n",
      "### LABELS:\n",
      "technical, AI-centric, subjective, definitional\n",
      "\n",
      "## CLAIM 2:\n",
      "CLAIM: \"It's hard to define exactly what an agent is.\"\n",
      "\n",
      "### CLAIM SUPPORT EVIDENCE:\n",
      "- The concept of an agent has been debated within computer science for decades, with varying definitions focusing on autonomy, reactivity, and social ability (Franklin & Graesser, \"Is it an Agent, or Just a Program?\").\n",
      "- Agents range from simple rule-based systems to sophisticated models involving machine learning and AI, complicating a universal definition (Wooldridge, \"An Introduction to MultiAgent Systems\").\n",
      "\n",
      "### CLAIM REFUTATION EVIDENCE:\n",
      "- While definitions can vary, a broad agreement exists that agents involve autonomous action and decision-making, indicating that a generalized definition is possible (Russell & Norvig, \"Artificial Intelligence: A Modern Approach\").\n",
      "- Standard definitions provided by accreditable bodies like ACM and IEEE can serve as reliable benchmarks.\n",
      "\n",
      "### LOGICAL FALLACIES:\n",
      "- **Hasty Generalization**: \"Everyone seems to have a slightly different definition\" generalizes without solid evidence for all stakeholders' views.\n",
      "\n",
      "### CLAIM RATING:\n",
      "B (High)\n",
      "\n",
      "### LABELS:\n",
      "complexity, definitional ambiguity\n",
      "\n",
      "## CLAIM 3:\n",
      "CLAIM: \"The more agentic your system is, the more an orchestration framework will help.\"\n",
      "\n",
      "### CLAIM SUPPORT EVIDENCE:\n",
      "- Complex systems with higher degrees of autonomy require robust orchestration frameworks to manage tasks, exceptions, and flows (Wiebe et al., \"Orchestration Frameworks for Automating Artificial Intelligence Systems\").\n",
      "- Real-world implementations of AI systems use frameworks like Kubernetes and Docker Swarm to achieve scalability and reliability (Google Cloud documentation on AI orchestration).\n",
      "\n",
      "### CLAIM REFUTATION EVIDENCE:\n",
      "- Some systems, regardless of autonomy levels, can operate efficiently using simpler orchestration methods (Lean and Efficient Workflow Orchestration in Cloud Computing, IEEE).\n",
      "- Not all applications need a sophisticated framework if their tasks are sufficiently delineated and simple (AWS Simple Workflow Service).\n",
      "\n",
      "### LOGICAL FALLACIES:\n",
      "- **Slippery Slope**: Suggesting increased complexity necessitates sophisticated frameworks without providing gradient evidence for all intermediate levels.\n",
      "\n",
      "### CLAIM RATING:\n",
      "B (High)\n",
      "\n",
      "### LABELS:\n",
      "technical, AI development, practical advice\n",
      "\n",
      "# OVERALL SCORE:\n",
      "\n",
      "LOWEST CLAIM SCORE: C\n",
      "HIGHEST CLAIM SCORE: B\n",
      "AVERAGE CLAIM SCORE: B-\n",
      "\n",
      "# OVERALL ANALYSIS:\n",
      "The argument provided is well-structured with valid points, though some claims lack universal applicability. The discussion on varying definitions of \"agent\" and \"agentic\" reflects the nuanced nature of AI. For clarity, assert definitions with broad consensus and cite diverse examples to support versatile applications.\n"
     ]
    }
   ],
   "source": [
    "response1 = wrapper(\n",
    "    analyse_claims,\n",
    "    new_web_text\n",
    ")\n",
    "print(response1.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.011420, Output: $0.008175, Total: $0.019595\n",
      "# Assessment of Content\n",
      "\n",
      "## Digest and Understand\n",
      "The content discusses the concept of an \"agent\" in the context of LLM (Large Language Model) applications, aiming to clarify what constitutes an agent, the varying degrees of agentic capabilities, and the importance of these capabilities in designing and managing such systems. The writer's intent appears to be to elucidate the technical nuances of agents while advocating for a broader understanding and better tooling for more agentic applications.\n",
      "\n",
      "## Identify Discrete Ideas and Novelty\n",
      "1. Definition of an agent.\n",
      "2. Variability in people's understanding of what an agent is.\n",
      "3. Concept of agentic behavior and its spectrum.\n",
      "4. Categorization of LLM systems based on their level of agentic behavior.\n",
      "5. Importance of understanding the degree of agentic behavior in developing LLM applications.\n",
      "6. Justification for developing new tools and infrastructure, such as LangGraph and LangSmith, for different agentic applications.\n",
      "\n",
      "### Novelty Evaluation\n",
      "- **Definition of an agent**: Technical definitions and common misconceptions. (B - Fresh)\n",
      "- **Variability in understanding**: General observance but highlights spectrum concept. (B - Fresh)\n",
      "- **Agentic behavior and spectrum**: The idea of different degrees of agentic capabilities. (A - Novel)\n",
      "- **Categorization of LLM systems**: Uses clear technical distinctions for agentic behavior. (B - Fresh)\n",
      "- **Importance of agentic understanding**: Practical insights on development, monitoring, and evaluation. (B - Fresh)\n",
      "- **Justification for new tools**: Introduction of LangGraph and LangSmith based on agentic needs. (A - Novel)\n",
      "\n",
      "### Combined Novelty Rating: B - Fresh\n",
      "\n",
      "## Clarity Evaluation\n",
      "- The article begins with an introduction, defines the term, discusses its variability, and delves into different levels of agentic behavior.\n",
      "- The explanation is generally clear, with explicit examples and logical flow. \n",
      "\n",
      "### Clarity Rating: B - Clean\n",
      "\n",
      "## Prose Evaluation\n",
      "- The prose is competent and generally clear, with some distinctive elements but occasional jargon and repetition.\n",
      "\n",
      "### Prose Rating: B - Distinctive\n",
      "\n",
      "## Recommendations for Improvement\n",
      "\n",
      "### Novelty\n",
      "- Introduce more unique case studies or applications.\n",
      "- Propose new frameworks for agentic behavior.\n",
      "- Provide a more detailed vision of future agentic systems.\n",
      "\n",
      "### Clarity\n",
      "- Simplify technical jargon when possible.\n",
      "- Break down longer paragraphs for better readability.\n",
      "- Summarize key points at the end.\n",
      "\n",
      "### Prose\n",
      "- Reduce repetition of \"agentic\" and related terms.\n",
      "- Add more distinctive, vivid examples.\n",
      "- Vary sentence structures for flow.\n",
      "\n",
      "## Overall Rating: B\n"
     ]
    }
   ],
   "source": [
    "response2 = wrapper(\n",
    "    analyse_prose,\n",
    "    new_web_text\n",
    ")\n",
    "print(response2.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Details: Input: $0.008255, Output: $0.013305, Total: $0.021560\n"
     ]
    }
   ],
   "source": [
    "response3 = wrapper(\n",
    "    extract_wisdom,\n",
    "    new_web_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SUMMARY:\n",
      "Harrison Chase of LangChain discusses the definition and nature of AI agents, their varying degrees of autonomy, and the importance of specialized tools and infrastructure to develop and monitor these systems.\n",
      "\n",
      "# IDEAS:\n",
      "1. An agent uses an LLM to decide the control flow of an application.\n",
      "2. Agents can be seen as systems that function on a spectrum of autonomy.\n",
      "3. Andrew Ng's viewpoint suggests categorizing agents by degrees of agentic capabilities.\n",
      "4. Levels of autonomy in LLM systems range from simple routers to complex autonomous agents.\n",
      "5. More agentic systems require specialized orchestration frameworks.\n",
      "6. Complex agentic systems need durable execution for error management.\n",
      "7. Interaction with agentic systems requires robust monitoring and evaluation frameworks.\n",
      "8. The agentic nature of a system determines tooling and infrastructure needs.\n",
      "9. Tools like LangGraph and LangSmith are essential for building and monitoring agentic systems.\n",
      "10. Evaluation frameworks for agentic systems need to test both final outputs and intermediate steps.\n",
      "11. Agentic systems require new types of monitoring to examine all steps taken by an agent.\n",
      "12. The agentic concept helps guide the development process for LLM systems.\n",
      "\n",
      "# QUOTES:\n",
      "1. “An agent is a system that uses an LLM to decide the control flow of an application.”\n",
      "2. “There are different degrees to which systems can be agentic.”\n",
      "3. “A system is more ‘agentic’ the more an LLM decides how the system can behave.”\n",
      "4. “Having an idea of how agentic your system can guide your decision-making during the development process.”\n",
      "5. “The more agentic your system is, the more an orchestration framework will help.”\n",
      "6. “The more agentic your system is, the harder it is to run.”\n",
      "7. “The more agentic your system is, the more you will want to interact with it while it’s running.”\n",
      "8. “The more agentic your system is, the more you will want an evaluation framework built for these types of applications.”\n",
      "9. “Understanding and leveraging the spectrum of agentic capabilities in your system can improve the efficiency and robustness of your development process.”\n",
      "10. “The more agentic your application is, the more critical it is to have new tooling and infrastructure.”\n",
      "11. “LangGraph, the agent orchestrator to help with building, running, and interacting with agents.”\n",
      "12. “LangSmith, the testing and observability platform for LLM apps.”\n",
      "\n",
      "# HABITS:\n",
      "1. Building tools that assist in developing LLM applications with varying degrees of autonomy.\n",
      "2. Engaging with diverse definitions and perspectives on AI agents.\n",
      "3. Utilizing the concept of agentic behavior in system design and development.\n",
      "4. Prioritizing robust and durable execution in creating complex systems.\n",
      "5. Regular evaluation and monitoring of agentic systems for efficiency.\n",
      "6. Continuous updates and reimagining of tooling and infrastructure for advanced AI applications.\n",
      "\n",
      "# FACTS:\n",
      "1. Agents are systems that use LLMs to decide application control flow.\n",
      "2. The concept of being \"agentic\" helps categorize systems based on their autonomy spectrum.\n",
      "3. Use of multiple LLMs and routing steps increases agentic behavior.\n",
      "4. Enhanced autonomy in agents requires advanced orchestration frameworks.\n",
      "5. Complex agentic systems face challenges in durability and error handling.\n",
      "6. Real-time interaction and observability are crucial for managing agentic systems.\n",
      "7. Andrew Ng advocates for viewing agent capabilities as a spectrum.\n",
      "8. New types of monitoring frameworks are necessary for highly agentic systems.\n",
      "9. LangGraph and LangSmith cater to the needs of building and observing agentic systems.\n",
      "\n",
      "# REFERENCES:\n",
      "1. Andrew Ng’s tweet on agentic capabilities.\n",
      "2. Voyager paper on advanced agent implementation.\n",
      "3. TED talk by Harrison Chase on LLM systems and autonomy.\n",
      "\n",
      "# RECOMMENDATIONS:\n",
      "1. Consider different degrees of agentic capabilities when designing AI systems.\n",
      "2. Utilize frameworks with support for branching logic and cycles for complex agents.\n",
      "3. Employ durable execution methods to manage complex agentic tasks.\n",
      "4. Implement robust monitoring to observe agent behavior in real-time.\n",
      "5. Use frameworks like LangGraph and LangSmith for building and testing advanced agents.\n",
      "6. Regularly evaluate both final outputs and intermediate steps of agentic systems.\n",
      "7. Design infrastructure and tools that cater to the level of agentic behavior in the system.\n"
     ]
    }
   ],
   "source": [
    "print(response3.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
