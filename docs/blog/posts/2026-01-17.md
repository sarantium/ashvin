---
title: Wardley Factories
date: 2026-01-17
tags:
  - wardley-mapping
  - AI
  - abstraction
---

The first industrial revolution made goods. The resistance of raw material to finished product—spinning cotton into thread, forging iron into rails—was the friction that defined an era. Then something shifted. The resistance moved up a level. We stopped just making goods and started making the machines that make goods. Resistance became: how do you build a factory? How do you systematize production itself?

This pattern recurs. Each time we solve the friction at one level, we create the conditions for the next level to become the bottleneck. And then we industrialize *that*. The resistance keeps moving up, and we keep following it, building machines to solve the problems created by the previous generation of machines.

Simon Wardley's evolution model—Genesis, Custom-Built, Product, Commodity—was supposed to describe how technologies naturally mature. Something new emerges (genesis), gets built bespoke for early adopters (custom), standardizes into products that compete on features (product), and eventually becomes undifferentiated infrastructure everyone assumes exists (commodity). The phases had a certain stateliness to them. You could watch a technology work through them over years, sometimes decades. The journey from ARPANET to commodity cloud computing took roughly forty years.

That stateliness is gone. What changed isn't just the pace but the structure. The Wardley phases have been industrialized. We've built factories for moving technologies through the evolution cycle, and those factories are getting more efficient with each iteration. The cycle that once took decades now completes in years; the cycle after that will complete in months. And each completion makes the next one faster, because the output of each cycle becomes the input for accelerating the next.

<!-- more -->

## The Compound Loop

Consider the sequence. Cloud computing commoditized infrastructure. That commoditization made it dramatically easier to build and deploy APIs—you no longer needed to provision servers, manage uptime, or handle scaling. APIs commoditized faster because they stood on commodity infrastructure. Then those commodity APIs made it possible to commoditize machine learning inference. You didn't need to train models or manage GPU clusters; you could call an endpoint. And commodity inference is now making it possible to commoditize... what, exactly?

The answer keeps shifting because the cycle keeps completing. Code generation. Design systems. Customer service. Legal document review. Each domain that seemed irreducibly complex turns out to be standing on substrates that just finished commoditizing. The moment the substrate beneath you becomes infrastructure, your domain enters the acceleration chamber.

This is compound interest, but for abstraction. Each layer of commodity infrastructure removes friction from the creation of the next layer. Removing friction removes learning time. Removing learning time means the next abstraction arrives before you've finished understanding the current one. The loop feeds itself.

The optimistic version of this story is familiar: productivity gains, democratized capabilities, the march of progress. And there's truth in it. A solo developer today can build systems that would have required a team of fifty a decade ago. The leverage is real.

But there's something the optimistic story doesn't account for: what happens to the people inside the loop?

## The Adaptation Window

Ibn Khaldun, the fourteenth-century historian, observed that dynasties follow cycles. The Bedouin who conquers has what he called *asabiyyah*: group feeling, solidarity forged through shared struggle. The next generation inherits the fruits without inheriting the struggle. By the third or fourth generation, the solidarity has dissolved. The dynasty falls.

This cycle took generations because the friction of transmission—parent to child, mentor to apprentice—was also the friction that allowed adaptation. The new generation had time to develop their own forms of solidarity, their own understanding of what held them together. The cycle renewed itself because people had time to learn what they needed to learn.

Compress that cycle from generations to years, and something breaks. The Wardley phases map disturbingly well onto Ibn Khaldun's dynasties. Genesis is the Bedouin moment: high risk, tight cohesion, small groups building from nothing. Custom-built is the early dynasty, still remembering how hard it was. Product is the settled urban life, comfort replacing necessity. Commodity is the decadent court, taking infrastructure for granted. But these phases used to require time. When the cycle completes in months, there's no window for adaptation. Each cohort reaches commodity before developing the solidarity that would let them recognize genesis conditions when they return.

There's a structural trap here. Systems require boundaries to learn: a distinction between what's inside and what's outside, between the experimental zone and the stable core. But successful learning dissolves those boundaries. The experiment graduates; the boundary disappears; the system that learned from the distinction has now eliminated the distinction. When acceleration compresses the cycle, you get adaptation without wisdom. The system changes faster than it can understand what the changes mean.

The friction that slowed the old cycles wasn't just resistance to overcome. It was the mechanism by which understanding accumulated. When the friction of creating something was also the friction of comprehending it, you couldn't build what you didn't understand. That constraint is gone. You can now generate systems whose complexity exceeds your ability to hold them in your head. The leverage is extraordinary. The disorientation is equally extraordinary.

Francisco Varela, the biologist who studied how organisms know their worlds, distinguished between two kinds of engagement. Spectatorial knowing treats ideas as objects to observe from the outside—you name them, categorize them, deploy them. Enacted knowing is different: the concept reorganizes your perception, changes what you can see and do. When you truly know something, you and it have co-determined each other. The superficial feeling—"I can use this framework but it hasn't changed me"—is the signature of spectatorial engagement. The concept became a tool without becoming a transformation.

The acceleration loop selects ruthlessly for spectatorial knowing. There's no time for structural coupling, for dwelling with material until reciprocal determination occurs. You acquire the label, maybe the definition, but no ontological shift happens. We're becoming tourists of our own abstractions—visiting ideas without inhabiting them, generating systems without understanding them, climbing ladders without knowing what we're climbing toward.

## The Ladder Problem

Here's what the productivity framing misses: we're not observers of this process. We're inside it. Our skills, our expertise, our professional identities—these are the raw materials for the next abstraction layer.

Each time a substrate commoditizes, the people who understood that substrate face a choice. You can climb the abstraction ladder, moving up to work at the next level where the friction now lives. Or you can become part of the infrastructure, your expertise absorbed into the commodity layer, your tacit knowledge encoded into systems that no longer need you to operate them.

This has always been true of technological transitions. The difference now is the rate. When the ladder rungs are added yearly, you can pace your climb. When they're added monthly, you're scrambling. When the acceleration is itself accelerating—when each rung creates the conditions for faster construction of the next rung—the scramble becomes the permanent condition. You're climbing while they build.

But there's a darker paradox lurking here. Arvind Narayanan observed that unlike previous technological transitions—machine code to assembly to high-level languages to frameworks—AI doesn't stabilize into predictable workflows. Once you systematize an approach, the agents can automate it. "The core task of software engineering thus becomes a constant process of finding ways to migrate ever-higher up the ladder of abstraction."

The trap: systematization is the signature of genuine understanding. When you truly comprehend something, you can teach it, structure it, make it repeatable. But in an era of AI coding agents, that very systematization creates the training data for your own obsolescence. Understanding well enough to codify is understanding well enough to be replaced. The clarity that was once the mark of mastery becomes the signal that this domain is ready for commoditization.

So we get a perverse selection pressure: stay illegible or become infrastructure. The things you can explain clearly are the things that can be extracted from you. The tacit knowledge that resists articulation—the intuition, the judgment, the "I can't quite explain why but this feels wrong"—that's what remains ungrabbed. For now.

The vertiginous quality of the current moment isn't "things are changing fast." That's been true for a century. The vertigo comes from recognizing that the rate of change is itself changing, that the acceleration has been industrialized, and that there's no obvious floor. Each abstraction layer creates the tools for abstracting the next layer faster. The loop has no natural stopping point.

## What Remains

There are two responses to this that don't work.

The first is nostalgia: a longing for the slower cycles, the craft knowledge, the time to understand. This fails because the clock doesn't run backward. The factories exist. The acceleration is structural, not cultural. You can't opt out by preferring the old ways.

The second is pure acceleration: a faith that if we just move fast enough, we'll stay ahead of the commoditization wave. This fails because the wave isn't external to you. Your acceleration is part of what creates the next wave. Moving faster doesn't get you out of the loop; it tightens it.

What might work—and I hold this provisionally, because I'm writing from inside the loop too—involves something more like orientation than strategy. Not escaping the acceleration but understanding your position within it.

*Provenance over position.* When everything can be generated, where code lives in a filesystem matters less than where it came from: what prompted it, what intention shaped it, what chain of transformations produced it. Organization becomes temporal and causal rather than spatial and categorical. This is the *isnad* principle from Islamic scholarship—the chain of transmission that authenticates the content—applied to an era of generated artifacts.

*Porosity over penetration.* The obvious response to acceleration is "go deep"—burrow into a domain so thoroughly that you can't be easily replaced. But Zhuangzi suggests a different framing: depth isn't vertical movement (penetrating further into territory) but porosity (the degree to which you can be affected, changed, made uncertain by what you encounter). The person who reads ten books and remains exactly who they were has gone nowhere. The person who reads one sentence and cannot sleep because something has shifted—that is engagement. In a world of accelerating abstraction, the measure isn't how far you've penetrated the idea but how much the idea has penetrated you.

*Friction by design.* Matthew Crawford, writing about motorcycle repair, observed that the resistance of material isn't an obstacle to understanding—it *is* understanding. When diagnosing an electrical fault, you're not free to interpret the wiring diagram however you like. The circuit completes or it doesn't. Depth comes from pushback. The modern intellectual environment optimizes for frictionlessness. Ideas flow. Everything is "interesting." But frictionlessness enables superficiality. Friction produces depth. What would jigs for thinking look like in an era of AI? Structures that hold attention on problems until you've actually worked through them. Teaching to students who ask naive questions. Building things that have to work. Apprenticeship arrangements where fakery becomes visible. Deliberately structured resistance that forces enacted knowing rather than spectatorial acquisition.

*The permanent experiment.* Zhuangzi tells of the crooked tree that lived to old age because no carpenter found it worth cutting. Its uselessness was its survival strategy. When the Wardley cycle demands that everything graduate from experiment to product to commodity, there's something to be said for the experiment that refuses graduation. Not every project needs to scale. Not every capability needs to be systematized. The things that stay particular, local, and unabsorbed may be the things that stay human.

*Build the Orbital.* Iain M. Banks's Culture novels describe superintelligent Minds who don't experience the depth-versus-breadth tradeoff. They engage with billions of concepts simultaneously at whatever depth each warrants—not because they're smarter but because they've solved the infrastructure problem. The heroic model of the solitary thinker achieving depth through concentration is, Banks suggests, tragic rather than admirable. A monument to inadequate cognitive infrastructure.

This reframes the question. Instead of asking "how do I go deeper?" ask "what would I need around me for depth to become easy?" The gardener doesn't choose between many plants or healthy plants; she creates conditions where both become possible. In an era where AI partnerships are possible, the question becomes: what cognitive infrastructure would make genuine understanding—not just spectatorial acquisition but structural coupling—the path of least resistance? The answer isn't willpower. It's environment design.

*The attention problem.* But here's what the infrastructure response misses: Iris Murdoch argued that the quality of attention is determined by the whole orientation of our being. The ego wants quick mastery—to "get" the idea and move on. The superficiality of modern intellectual work isn't methodological but characterological. The same selfishness that prevents us from truly seeing another person prevents us from truly seeing an idea. We translate the unfamiliar into the familiar too quickly—"Ah yes, this is like X"—and that translation is refusal. We refuse to let the thing be itself.

The acceleration loop feeds the ego's tempo. More, faster, leverage. But enacted knowing requires dwelling—staying with material long enough for reciprocal determination to occur. You and the thing you're trying to understand have to co-constitute each other, and that takes time the loop doesn't grant.

So there's a tension at the heart of any response: infrastructure can make depth easier, but the person deploying the infrastructure may lack the capacity for attention that depth requires. Build better environments *and* practice unselfing—the gradual dismantling of the ego's interference with seeing. Both are necessary. Neither is sufficient.

None of this is a solution. The loop doesn't have a solution, any more than compound interest has a solution. The question isn't how to stop it but how to remain oriented while it operates.

The fishing village that became Shenzhen did so through bounded experimentation—Special Economic Zones where different rules applied, where the chaos of genesis could unfold without destabilizing the stable core. Maybe the equivalent for navigating the Wardley factories is something similar: bounded spaces where you can understand what you're building, where the cycle deliberately slows, where the friction of creation is preserved because that friction is also the friction of comprehension.

The ladder keeps extending upward, each rung built from the rungs below. Somewhere in that recursion, you're standing on a rung that's about to be absorbed. The factories are running. The only question is whether you know which factory you're in.
